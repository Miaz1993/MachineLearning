# 《美团机器学习实战》

## 总结

这是一本很好的梳理了机器学习在真实场景中的应用实例。在我看来此书有两个突出的优点，值得推荐：（1）本「xx实战」书和通常意义上的实战书有所不同，它不像《机器学习实战》那样教你手把手的写代码，而更多的是梳理各个技术的基础体系和适用场景，以及在落地过程中的思考方式和经验。（2）虽然其本书称为「美团机器学习xx」，但内容并未局限于此，本书所梳理的内容是通用的，很具有借鉴意义，透过真实的应用场景有能让读者有更直接的感触，从这一角度本书优于《机器学习在线：解析阿里云机器学习平台》。

但本书有些美中不足的是，有些点写得还是过于深入，阅读过程中若有负担可跳过理论部分。另外是对某些章节的说明，第五章「POI 实体链接」和美团最近，若没有需要可跳过。深度学习部分，13～15章偏重科普，可以看看演变历史和美团在此方面的应用即可。值得着重一提的是算法工程部分，16 章“大规模机器学习” 和 17 章 特征工程和实验平台，梳理了真实场景下的机器学习平台框架，值得作为架构设计的参考。


## 目录

前言：本书历时一年完成，是各个部门的算法工程师们利用业余时间撰写的结晶。

- [通用流程](#general-pipline)：
	- [x] [1. 问题建模](#01)
	- [x] [2. 特征工程](#02)
	- [x] [3. 常用模型](#03)
	- [x] [4. 模型融合](#04)
- [数据挖掘](#data-mining)：
	- [x] [5. 用户画像](#05)
	- [x] [6. POI 实体链接](#06)
	- [x] [7. 评论挖掘](#07)
- [搜索和推荐](#search-recommendation)：
	- [x] [8. O2O 场景下的查询理解与用户引导](#08)
	- [x] [9. O2O 场景下排序的特点](#09)
	- [x] [10. 推荐 O2O 场景中的应用](#10)
- [计算广告](#computing-advertising)：
	- [x] [11. O2O 场景下的广告营销](#11)
	- [x] [12. 用户偏好和损失建模](#12)
- [深度学习](#deeplearning)：
	- [x] [13. 深度学习概述](#13)
	- [x] [14. 深度学习在文本领域中的应用](#14)
	- [x] [15. 深度学习在计算机视觉中的应用](#15)
- [算法工程](#algorithm-engineering)：
	- [x] [16. 大规模机器学习](#16)
	- [x] [17. 特征工程和实验平台](#17)

<h2 id="general-pipline"> 通用流程 </h2>

<h3 id="01"> 1. 问题建模 </h3>

- 评估指标：通常线下使用**机器学习评估指标**，线上使用**业务评估指标**，注意两者的一致性。
    - 分类指标：
        - 精确率和召回率： Precision/Recall, F1-score, F-alpha 调和加权, 注意精确率（二分类指标）和准确率（多分类的指标）的区分。  
        - ROC 与 AUC
        - Logistic Loss (logloss)
    - 回归指标：
	     - Mean Absolute Error (MAE), 也叫 L1-norm Loss. Weighted Mean Absolute Error (WMAE).  
	     - Mean Absolute Percentage Error (MAPE) 
	         - 优点：与量纲无关，因此在特定场景下不同问题具有一定可比性。
	         - 缺点：在 yi=0 处无定义，并且如果 yi 接近 0 会导致 MAPE 大于 100%；对负值误差的惩罚大于正值误差。基于这些缺点，有一些改进指标，比如 MASE, sMAPE, MDA.
         - Root Mean Squared Error (RMSE)
            - 特点：和 MAE 比, RMSE 对大误差样本有更大的惩罚。
            - 缺点：对离群点敏感。
            - 有一个常用的变种 Root Mean Squared Logarithmic Error (RMSLE)
    - 排序指标：
        - 平均准确率均值（Mean Average Precision, MAP）
        - Normalized Discounted Cumulateive Gain (NDCG)
- 样本选择：非常重要的环节，主要目的是从海量数据中识别和选择相关性高的数据作为机器学习模型输入。
    - 做好样本选择主要有以下 3 点：
        - 数据量过大带来的困扰。
        - 没有必要使用全部数据，相关性太低的数据对解决特定问题可能没有帮助。
        - 去除噪音
    - 数据去噪
        - 识别出噪声后，可以采用**直接过滤**或者**修改噪声数据**等多种做法。
        - 噪声的多样性：特征值不对（比如缺失、超出合理阈值）；标注不对等。
        - 针对误标注实例有很多成功的处理方案：Ensemble Filter (EF), Cross-Validated Committees, CVCF), Iterative-Partitioning Filter (IPF). 都是基于融合或者投票的思想。除了以上方法之外，还会结合业务场景进行噪音过滤，比如清洗爬虫中不具有代表性的文本。
    - 采样
        - motivation：降低成本，缩短时间甚至提升效果。
        - 简单介绍 5 种采样方法：
            - 无放回简单随机抽样（Simple Random Sample Without Replacement）
            - 有放回简单抽样（Simple Random Sample With Replacement）
            - 平衡采样（Balanced Sample）：在不平衡分类中有十分成功的应用
            - 整群采样（Cluster Sample）。
            - 分层采样（Stratified Sample）
    - 原型选择和训练集选择：
        - 原型选择，根据从数据集中选择样本集的方向划分：增量法、递减法、批量法、混合法、固定法、
        - 原型选择，根据选择样本的策略划分：包装器、过滤器   
        - 原型选择，根据选择的样本划分：Condensation, Edition, Hybrid.
- 交叉验证
    - 留出法：
        - 优点：简单好实现
        - 缺点：不能充分利用数据训练模型，并且训练集和测试集的划分严重影响最终结果。
        - 其他：实际工作中有一种普遍的应用场景广泛使用留出法，数据有明显的时间序列因素。
    - K 折交叉验证
        - 关键参数：K 影响实验的稳定性；太小会导致稳定性偏低，但太大导致实验成本高，最常用的值为 5 和 10.
        - 特点：能够更好地避免过拟合和欠拟合，得到的结果更有说服力。相比留出法，更为复杂，但数据利用率更高。当 K=N 时，等于 Leave-One-Out (LOO)是，在数据稀疏时很试用。由此改进得到的 Stratified K-Fold 在类不均衡情况下常用。
    - 自助法（Bootstrapping）
        - 以自主采样（Bootstrap Sampling）为基础。经过 n 次采样还没有被采到的概率是 0.368。
        - 优点：留出法和K-fold-corss-validation 在训练模型时用的数据都只是整个数据集的一个子集，得到的模型会因为训练集大小不一致产生一定偏差。自助法能够更好地解决这个问题。
        - 缺点：改变了初始数据集的分布，会引入估计误差，所以在数据量足够时，一般采用留出法和交叉验证法。在数据量小，并且难以有效区分训练集和测试集时，自助法很有用。            

<h3 id="02"> 2. 特征工程 </h3>

- 前言
    - “数据和特征决定了机器学习算法的上限，而模型和算法只是不断逼近这个上限而已”。足够和优质的数据是特征工程的前提。 
- 特征提取
    - 前言：
        - 操作流程：1. 了解现有数据，可以获取的数据和获取成本等；2. 从现有数据中挖掘对机器学习模型有用的特征（最主要的挑战）。
        - 目标：对业务数据和业务逻辑进行精准、全面的描述。
        - 思路：根据机器学习算法所要学习的目标和业务逻辑，考虑数据中有哪些可能相关的要素。  
    - 探索性数据分析（Exploratory Data Analysis, EDA）是采用各种技术（大部分为可视化技术）在尽量少的先验条件下，探索数据内部结构和规律的**一种数据分析方法或理念**。
    - 数值特征
        - Tips
            - 主要考虑的因素：大小和分布。
            - 对于那些目标变量为输入特征的光滑函数的模型（如线性回归、逻辑回归等），其对输入特征的大小很敏感。因此，当使用光滑函数建模时，有必要对输入进行归一化。
            - 特征的交叉组合。
        - 8 种常见的数值特征处理方法：
            - **截断**：对于连续型数值特征，有时候太多的精度可能只是噪声。
            - **二值化**：计数特征，比如网站每天访问量、餐厅评论数，是否要转为二值变量（是/否）处理。
            - **分桶**：如果数值数据跨越不同的数量级，那么这不是一个好的特征，模型往往只关注值比较大的特值敏感。通常解决该问题的方法是分桶，有均值分桶、分位数分桶。分桶也可以看作数据离散化的操作。
            - **缩放**：缩放即对数值变量缩放到一个确定的范围。常见的缩放有：标准化缩放（z-normalization，对那些光滑函数模型，如线性回归、逻辑回归等对特征大小很敏感的模型，有效）、最大最小值缩放、基于某种范数的归一化（如 L1, L2）、平方根缩放或对数缩放（对处理长尾有效）、Box-Cox。对于异常数据可以使用更加健壮的缩放，一般使用中位数而不是均值，使用分位数而不是方差。
            - **缺失值处理**：（1）补充一个值：均值、中位数、预测一个值；（2）直接忽略，比如 XGBoost 模型可以处理缺失特征。
            - **特征交叉**：特征交叉可以表示数值特征之间的相互特征。引入非线性性质，提升模型的表达能力。手工：加减乘除等；模型：FM,FFM。
            - **非线性编码**：提升线性模型的效果。（1）多项式核、高斯核等（核函数不好选）。（2）将随机森林模型的叶节点进行编码喂给模型。（3）基因算法以及局部线性嵌入、谱嵌入、t-SNE等。
            - **行统计量**：直接对行向量进行统计。比如统计行向量中空值的个数、0的个数、正值或负值的个数，以及均值、方差、最小值、最大值、偏度、峰度等。   
    - 类别特征
        - **自然数编码**：每一个类别分配一个编号。
        - **独热编码**：直接将自然数编码喂给模型，往往效果很差，尤其是线性模型，因为对于其取值大小没有物理含义。常用独热编码将每个特征转为一维特征。
        - **分层编码**：比如邮政编码核身份证号等类别特征，可以取不同位数进行分层，然后再进行自然数编码。需要专业领域知识。
        - **散列编码**：当特征取值特别多时，使用独热编码得到的特征矩阵非常稀疏，因此在此之前可以先对类别进行散列编码。注意：特征值可能冲突导致模型效果降低。
        - **计数编码**：将类别特征用其对应的计数来代替。对异常值敏感，特征取值可能冲突。
        - **计数排名编码**：对异常值不敏感，不发生冲突。
        - **目标编码**：针对基数（类别变量所有可能不同取值的个数）很大的离散特征，例如 IP 地址、网络域名、城市名、家庭地址、街道、产品编号等，上述预处理方法效果往往不好。对于高基数类别变量，一种有效方式则是基于目标变量对类别特征进行编码，即有监督的编码方法。例如在广告点击率预测问题中，我们计算广告主 ID 在过去固定一段时间内的点击率，对广告主 ID 进行目标编码。
        - **类别特征之间交叉组合**：（1）类别间的笛卡尔积；（2）特征组合方式是基于统计的组合，多维度的统计特征，比如某个城市有多少不同的商品 ID 以及当前 ID 出现次数的分布。一般从业务逻辑的角度出发进行构造。
        - **类别特征和数值特征之间交叉组合**：例如针对用户 ID，统计过去一段时间内在网站上的浏览次数、购买次数、以及购买价格的统计量。可以看作是利用数值特征对类别特征进行编码。
    - 时间特征
        - 基于时间本身的特征：比如浏览、购买、收藏的时间
        - 时间序列相关的特征：比如股票、天气温度、降雨量 
    - 空间特征
        - 比如经纬度，地理区块上的特征等。 
    - 文本特征
        - **语料构建**
        - **文本清洗**：在某些情况下，文本不一定需要清洗，取决于具体场景。例如考虑某编辑员对某物品的描述，如果我们关心的对象是物品，则需要去除噪声，保留关键信息，但如果我们关心的对象是编辑员，则噪声信息一定程度上反映了此编辑员的水平。
        - **分词**：
            - **词性标注**：最重要的 3 类，名词、动词和形容词
            - **词形还原和词干提取**
            - **文本统计特征**
            - **N-Gram模型**
        - **Skip-Gram模型**：词集模型、词袋模型、TF-IDF、余弦相似度、Jaccard 相似度、Levenshtein (编辑距离)、隐性语义分析、Word2Vec  
- 特征选择
    - 目的：
        - 简化模型，使模型更易于研究人员和用户理解；
        - 改善性能；
        - 改善通用性、降低过拟合风险。
    - 一般流程：产生过程、评价函数、停止准则、验证过程。   
    - 过滤方法
        - 特点：不需要依赖任何机器学习算法。优势是与算法独立，灵活高效。
        - 流程：特征全集--->特征选择--->机器学习算法--->模型效果
        - 常用方法：覆盖率，Pearson 相关性，Fisher 得分，假设检验，互信息，最小冗余最大相关性，相关特征选择。
    - 封装方法
        - 过滤方法没有考虑选择的特征集合咋爱具体机器学习算法上的效果。封装方法直接使用机器学习算法评估特征子集的效果。缺点：样本不够充分的情况下容易过拟合；特征变量较多时计算复杂度太高。
        - 常用的几种特征子集搜索算法：完全搜索、启发式搜索。 
    - 嵌入方法  
        - 特点：将特征选择嵌入到模型的构建过程中，具有封装方法与机器学习算法相结合的优点，而且具有过滤方法计算效率高的优点。**嵌入方法是实际中最常见的方法**。典型的方法有：LASSO和基于数模型的特征选择方法。
- Tools: 若数据量较小，Sklearn 的 feature_selection；若数据量较大，Spark MLib。

|  特征选择方法 | |  优点  | 缺点   |  举例  |
|---|---|---|---|---|
| 过滤方法 |单变量   | 速度快<br>可扩展<br>跟机器学习模型独立  |忽略特征之间的关系<br>忽略了特征和模型之间的关系   | 卡方检验<br>信息增益<br>相关系数| 
|         |多变量   |考虑了特征之间的相关性<br>跟机器学习模型独立<br>计算复杂度优于封装方法   |计算速度和可扩展性低于单变量的方法<br>忽略了特征和模型之间的关系   |基于相关性的特征选择(CFS), MBF, FCBF |
| 封装方法 |确定性算法    |简单<br>跟机器学习模型相关<br>考虑特征之间的相互作用<br>计算密集程度低于随机算法   |容易过拟合<br>相比随机算法容易卡在局部最优子集（贪心搜索）<br>依赖机器学习模型   |序列向前特征选择（SFS）<br> 序列向后特征删减（SBE）<br> 增q删r |
|        |随机算法    | 不容易达到局部极小点<br>跟机器学习模型相关<br>考虑特征之间的相互作用   |计算密集型<br>依赖机器学习模型<br>相比确定性算法过拟合的风险较高   |模拟退火 <br> 随机爬山 <br> 基因算法 |
| 嵌入方法 |    |与模型相关<br>计算复杂度优于封装方法<br>考虑特征之间的相互作用   |依赖机器学习模型   |决策树、随机森林、梯度提升数<br>SVM<br>LASSO |


<h3 id="03"> 3. 常用模型 </h3>

主要介绍其中三种在工业界和美团应用十分广泛的模型——逻辑回归、场感知因子分解机和梯度提升树。

- 逻辑回归
    - 逻辑回归原理
        - 实际上，为了提高算法收敛速度和节省内存，实际应用在迭代求解时往往会使用**高效的优化算法，如 LBFGS、信赖域算法等**（LibLinear, Spark MLib 里的 LR 是基于 LBFGS 实现的）。但这些方法都是基于**批处理**的，批处理算法**无法高效处理超大规模的数据集，也无法对线上模型进行快速实时更新**。  
        - **随机梯度下降**是对于批量处理的另外一种优化方法，每次只用一个样本来更新模型的权重，这样就可以更快地进行模型迭代。**对于广告和新闻推荐这种数据和样本更新比较频繁的场景，快速的模型更新能够更早捕捉到新数据的规律进而提升业务指标**。
        - 现在很多公司线上使用的是谷歌的 FTRL 算法，它是基于随机梯度下降的一种逻辑回归优化算法。
    - 逻辑回归应用
        - 常用的场景：自动诊断、经济预测、点击率预测等领域；
        - 适用情况：需要大规模训练的样本和特征，对于广告十亿量级的特征具有天然优势；
        - 优点：处理速度快且容易并行
        - 缺点：需要大量特征组合和离散的工作来增加特征的表达性，模型表达能力弱，比较容易欠拟合；
        - 研究热点：稀疏性、准确性、大规模计算。 
- 场感知因子分解机（Field-aware Factorization Machine, FFM）：自动做特征组合，并且算法效率比较高
    - 因子分解机原理
        - 因子分解机施加的限制是要求二次项参数矩阵是低秩矩阵的乘积。 
    - 场感知因子分解机原理
        - 进一步降低特征间的相关性。引入特征组（场）的概念来优化这个问题。 
    - 场感知因子分解的应用 
        - FFM 可以自动做特征组合和处理高维稀疏特征，因而它在处理大量离散特征的问题上往往有比较好的效果。使用 FFM 时，要注意对连续特征做归一化和离散化。
        - FM, FFM 与其他模型的对比关系：
            - FM 和 FFM：FFM 在 FM 的基础上引入了场的概念，可以认为 FM 是 FFM 的特殊简化模式。
            - FM 和 神经网络：神经网络难以直接处理高维稀疏的离散特征，因为这导致神经元的连接参数太多。而因子分解机可以看作对高维稀疏的离散特征做嵌入（Embedding）。
            - FM 和 梯度提升树：当数据不是高度稀疏时，梯度提升树可以有效地学习到比较复杂的特征组合；但是在高度稀疏的数据中，特征二阶组合的数量就足以让绝大多数模式找不到样本，因而梯度提升树无法学习到这种高阶组合。
            - FM 与 其他模型: FM 是一种比较灵活的模型，通过合适的特征变换方式，FM 可以模拟二阶多项式核的支持向量机模型、MF 模型、SVD++ 模型等。但 SVD++ 与 MF 在特征的扩展性上都不如 FM，而支持向量机核函数计算复杂度较高。
- 梯度提升树：广泛使用的是 XGBoost 和 LightGBM
    - 梯度提升树原理
        - 梯度提升树算法是集成学习 Boosting 家族的一员，它在训练时采用前向分步算法，首先确定第一棵树拟合的值，然后基于之前所有树的误差来更新训练下一棵树，一步一步迭代下去直到梯度提升树模型构建完毕。
        - XGBoost 是 Boosting Tree 的一种实现，它对损失函数进行了二阶泰勒展开，同时用到了一阶和二阶导数，并引入了适用于树模型的正则项用于控制模型的复杂度。
    - 梯度提升树的应用 
        - kaggle 比赛获胜模型往往是梯度提升树，后来是 XGBoost，对于非结构化数据，获胜的几乎都是人工神经网络。
        - 梯度提升树与其他模型的对比：
            - 梯度提升树算法与线性模型：梯度提升树可以更好的处理缺失特征、不在同一区间的特征、异常点、特征间的相关性、非线性决策边界的问题。
            - 梯度提升树算法与随机森林：随机森林可以并行训练，较不容易过拟合。梯度提升树可以学习更复杂的决策边界，效果往往会更好。
            - 梯度提升树算法与神经网络：中小数据集采用 XGBoost，数据集较大时采用神经网络。  

<h3 id="04"> 4. 模型融合 </h3>

- 前言
    - 模型融合(Model Ensemble）有时也被称为多分类器系统（Multiple Classifier System）或基于委员会的学习（Committee-Based Learning）。
    - 主要包含两个阶段：（1）构建若干单模型（Single Model），也称为基学习器（Base Learner）、个体学习器（Individual Learner）或者组建学习器（Component Learner）。（2）模型融合，可分为同质模型融合（Homogeneous Model Ensemble）和异质模型融合（Heterogeneous Model Ensemble）。
    - 模型融合、集成学习和群体智慧在本质上是相通的，即认为“群体决策通常比个体决策更优”。 
- 理论分析
    - 融合收益 
        - Dietterich 在 2000 年提到，模型融合能够比单模型具有更强的泛化能力。这可以从三个角度来解释。
        - 从统计的角度来看：在没有充分数据的情况下，学习任务会找到多个能够达到同等性能的假设空间。通过融合方式来平均这些模型预测的结果，**可以降低预测错误的风险**。
        - 从计算的角度来看：模型融合可以看作对同一份训练集、从很多不同起始点进行局部搜索，然后进行结合。这样可以**降低陷入糟糕的局部极小点的风险**，从而得到一个更好的对真实假设的近似。
        - 从表示的角度来看：模型融合可以使假设空间扩大，从而使得这些学习任务可能得到正确的表示。 
    - 模型误差——分歧分解（Error-Ambiguity Decomposition）：**单模型应该“好而不同”**。
    - 模型多样性度量
        - 成对的多样性度量：不一致度量、相关系数、Q 统计、K 统计、双次失败度量；
        - 非成对的多样性度量：KW 差异、批判一致性度量、熵度量、难点度量。
    - 多样性增强
        - 思路：引入**随机性**，常见的做法主要是对数据样本、输入属性、输出表示、算法参数进行扰动。
        - **数据样本扰动**：由初始数据集产生不同的数据子集，再利用不同的数据子集训练出不同的单模型。
        - **输入属性扰动**：注意当属性较少时，不宜使用。
        - **输出表示扰动**：基本思路是对输出表示进行操纵以增强多样性。比如将多分类任务转为多个二分类任务来训练单模型；还有“翻转法”，“输出调制法”。
        - **算法参数扰动**：调参。 
- 融合方法
    - **平均法**
        - 加权平均法可以看作集成学习的一个基本框架，不同的集成学习方法可以看作通过不同的方式来确定单模型的权重。
        - 简单平均法得到的融合模型误差小于等于单模型的平均误差。
        - 一般来说，预测效果较好的单模型权重应该设置大一些，表现稍差的单模型权重设置小一些。
        - 加权平均法的权重也可以从训练数据中学习而得到。但一般情况下不可行。
        - 实验和应用均显示，加权平均法未必一定优于简单平均法。广泛比较认可的策略是：当单模型性能表现比较一致时，采用简单平均法比较好；当单模型差异性比较大时，采用不同权重的加权平均法更合适。 
    - **投票法**
        - 对于分类任务来说。
        - 根据单模型输出类型，该标记向量可能有两种形式：**分类标记**对应**硬投票法**，**分类概率**对应**软投票法**。
        - 几种常用的方法：
            - 硬投票法：绝大多数投票、相对多数投票法、加权投票法
            - 软投票法：（1）对模型的输出进行规范化后作为类概率使用；（2）将输出转为类标记处理。  
    - **Bagging**
        - 1996年由 Breiman 提出，有两个关键 Bootstrap 和 Aggregation. 通过自助采样产生 m 个样本对应 m 个单模型。
        - Bagging 属于并行算法。
        - Bagging 采用重采样的方式，各个模型之间的相关性不高，所以可以降低variance。即降低了模型的过拟合风险。 
    - **Stacking** 
        - 1992 年被 Wolper 提出。基本思路是，通过一个模型来融合若干单模型的预测结果，目的是降低单模型的泛化误差。
        - 一般使用训练一级模型未使用的样本来产生二级模型的训练集。交叉验证法或留一法是比较常用的方法。 

<h2 id='data-mining'> 数据挖掘 </h2>

<h3 id="05"> 5. 用户画像 </h3>

- **什么是用户画像**
    - 用户画像这一概念在业界没有目前没有明确的定义，最早是 Alan Cooper 在《About Face: 交互设计精髓》一书中，研究用户系统化方法时提出了用户模型的概念。**用户模型指真实用户的虚拟代表，是在深刻理解真实数据的基础上得出的一个虚拟用户。**可以通过调研去实现。
    - 用户画像要解决的主要问题，就是使用这些纷繁复杂、没有直接商业价值的数据，通过清晰、挖掘、整理，生产出能够直接指导商业运营的用户属性体系，包括人口属性、行为轨迹、用户分群、生活场景、消费偏好等，这些属性需要有明确的层级划分和可理解性。
    - 美团的标签体系：通常有好几个等级，大分类通常包括：人口属性、兴趣偏好、特征人群、用户分级、LBS 属性、用户行为、业务标签。
- **用户画像数据挖掘**
    - 从开发实现的角度来说，通常分为两大类
        1. 经过策略统计分析直接得到；
        2. 通过机器学习训练模型，然后基于模型预测得到。（本节重点）
            1. 收集样本集合建立机器学习模型；
            2. 在全量数据上做预测计算。
    - 画像数据挖掘整体架构：通常包括数据收集、数据清洗、特征生成、标签建模、预测计算、效果评估、线上应用、效果反馈等多个环节。下面是美团的用户画像系统结构（书本有图）
        - 数据收集：数据挖掘的天花板是数据本身，因而数据收集需要有开阔的视野：自产数据+爬取数据+第三方合作数据。最终数据汇聚到基于 Hadoop 生态的数据仓库。
        - 特征计算：HDFS, Hive, MR, ETL, Storm, Spark --> FeatureCollector, FeatureSpider. （美团自己开发了 FeatureSpider，可以自动发现特征的工具）。
        - 特征库维护：统一存储和维护特征。FeatureCollector, 特征库。
        - 机器学习模型：Spark MLlib, EnsembleLearning, TensorFlow, Feature AutoFilter, ParamAutoSearch, SKlearn, XGBoost, DeepLearning4j, MT MLlib, PMML...
        - 应用接口：标签库，UPS, Flame, USS, LookAlike, UTVS, TCS。
        - 画像应用：精细化运营、个性化推荐、商业分析、风控、金融征信、个性展示...  
    - 用户标识：
        - 在现实生活中，一个人的身份ID就唯一标识一个人。但在用户画像的过程中，用户标识的选取和设定就没那么简单，很多时候会根据不同的场景选取不同的用户标识。
        - 建立自然人的概念，从自然人的维度将用户画像统一起来。**自然人，一般简称为 NPI(Natural Person Identification)**。一个用户通常会有多个 ID (userID/deviceID/Mobile/Payaccount/Email/QQ/identityID/unionID)，实际上各种 ID 之间有关联（浏览：userID=>deviceID, 绑定：userID=>Mobile，支付：userID=>Payaccount）。这些有关联的ID一起构成一个实际的用户，也就是自然人；来自用一个用户的所有 ID 统一对应到一个唯一编号 NPI。 
    - 特征数据：
        - 解决用户相关数据的收集问题。
        - 为了高效挖掘用户标签，要避免重复提取特征数据，降低人力成本和减少时间的浪费；在进行具体的标签挖掘之前，需要先进行用户特征库的规划和建设。
            1. 从整体上对用户数据进行梳理归类：账号属性特征、第三方数据特征、LBS 特征；
            2. 公司内部数据+公司外部数据；用户直接相关数据+用户间接相关数据。
        - 随着特征数据的增加，这样虽然部分解决了特征稀疏的问题，同时也带来其他新的问题，如机器学习里常常需要面对的维度灾难问题、无关垃圾特征、特征加工激增、特征质量保障难度增加问题等。
    - 样本数据
        - 主要是用有监督的机器学习，面临以下挑战：样本缺失、样本少、单样本等。
        - 主要采用**找、转、试**三种方式来加以解决
            1. “找”样本，通过问卷的方式、内部员工数据、人工标注以及用户注册服务提交数据等；
            2. “转”，一些问题进行转换，变成可按时间切分的预测问题，可以按时间的先后顺序来自动标注样本，如用户偏好类问题转换成用现在预测未来的问题，用点击/购买等行为作为标注。
            3. “试”验学术论文中实验效果比较好的一些学习方法。比如 Self-Train/Co-Train/Tri-Train, Transductive SVM, One-Class-SVM/Biased-SVM/SPY技术/NB技术等。
    - 标签建模
        1. 建模方法，
            - 2个主要挑战：
                1. 标签建模系统不可或缺；
                2. 用户画像标签的类型比较广泛，会涉及分类问题、回归问题、语义分析问题、协同问题等，因此优化目标同样比较广泛。
            - 离线标签生产平台简介
                - 公司内部研发了一套标签生产平台——DMSPA(DM 是数据挖掘的缩写，SPA 代表享受的事情，寓意这个平台将数据挖掘变成一个快乐的事情)。
                - 存储层：HDFS, MySQL, S3 等。HDFS 用于存储特征数据、训练数据等大规模数据； MySQL和S3用于存储一些配置文件、资源文件等小文件。
                - 计算资源：Hive, Spark，用于特征抽取、变换等批处理操作
                - 平台模型：封装了一些开源的机器学习库：Spark MLlib, Sklearn, DMLC, TensorFlow 等。
                - 整个数据挖掘流程分成 4 个部分：特征库/样本库、特征定制、模型构建和模型发布。
                - 平台还包括一个 Web 系统，提供用户界面，让用户通过可视化的界面对底层的模型进行调用，完成建模任务。
            - 标签生产流程简图
                - 标签生产平台：
                    - 将特征库、特征处理、特征监控、样本库、模型训练、模型预测、标签质量监控等模型进行了有机的整合。  
                - 实时标签建模系统
                    - 实时特征模块：
                        - Flume & Kafka(高吞吐量的分布式消息系统), 
                        - Storm(Twitter开源的分布式实时大数据处理框架，可以非常容易地像 Hadoop 批量处理大数据一样做到可靠处理实时的数据流。使用非常简单，支持任何变成语言。解决了实时处理复杂数据的痛点：需要维护一堆消息队列和消息者及其构成的复杂的图结构)。
                    - 实时计算模块：
                        - 实时标签从生产的角度看分为两种：
                            - **用户行为出触发的标签**：由用户行为触发，生产入库后一段时间内标签值保持不变（除非超过一定时间后过期失效）；
                            - **用户请求触发的标签**：由用户请求触发，每次请求都会由于当前的上下文参数（如当前的浏览页面、经纬度定位、时间戳等）等因素发生变化而导致标签值发生变化。
                - 标签挖掘算法经验
                    - 特征工程：
                        - 特征提取：美团点评 log/WEB 公共数据抓取/第三方合作
                        - 特征监控：
                            - 覆盖率/异常值/实效性/...
                            - 可视化/预警
                        - 特征处理
                            - 特征清洗：异常过滤/竞对爬虫/监控流量
                            - 特征预处理：
                                - 值处理
                                    - 平滑/归一化/离散化
                                    - 特征编码（one-hot/dummy-coding/...）
                                - 特征选择
                                    - Filter: 卡方，信息增益，交叉熵，Fisher, FastRegression。
                                    - Embedded: LOSS + L1, 树模型，MaxEnt
                                    - Wrapper: 遗传算法/前向法/后向法
                                - 特征组合：GBDT/RF/DNN/FM
                                - 降维：
                                    - PCA/LDA
                                    - MF(SVD/ALS)s       
                    - 模型使用经验
                        - 用户建模标签挖掘过程涉及的模型多样，包括统计、语义分析、高维偏好、分类、回归、聚类等。
                        - 面对多样的标签与多重的问题，扣紧实际的需求场景，进行场景设定和具体问题限制，往往能将问题简化很多而且取得不错的效果。此外，**Keep It Simple**.
                        - 不同模型会有不同的假设条件和适合的场景。比如 DNN 在用户画像建模中不理想。    
        2. 建模实例
            - 基于规则的标签挖掘
            - 样本明确的标签挖掘：利用已获得的有标注的用户，对用户行为进行分析，利用监督学习模型，找出用户行为与标签的内在联系，对没有标注的用户进行预测。
            - 小样本问题及单样本数据挖掘：
                - 从少量已标注数据和无标注数据中学习称为**Lu Learning**：
                    - Self-Training，最简单也最容易实现的半监督学习模型，缺点主要是错误分类的样本对后续训练有较大的累积影响；
                    - Co-Training，该算法假设数据属性拥有两个充分冗余的视图，然而在实际数据集较难满足，其改进算法包括 Tri-Training。 
                - 从正例和无标注数据中学习称为 **Pu Learning**：
                    - 直接法：直接对单样本建模，比如 V-SVM, One-Class-SVM, Biased-SVM
                    - 两步法：通过转化后将 Pu Learning 问题转换为普通分类问题，比如 Spy, 1DNF, NB 等技术。
            - 用户实时标签挖掘
                - 在实际应用时，一般不会对每一时刻建模，而是以用户的实际点击作为分解点，这样产生的样本与实际数据分布一致，同时和业务应用逻辑更加契合。
            - 实例解析——用户常驻城市预测 
- **用户画像应用**
    - **从画像数据的应用场景来讲，用户可能通过用户标识来查询该用户的画像数据，也可能通过画像数据来搜索满足条件的用户列表，甚至需要根据画像数据作为约束条件来定义人群，然后在人群的基础上做进一步的聚合分析、可视化展示等。** 
    - 用户画像实时查询系统
        1. 架构设计：离线数据 + 线上数据
        2. Lambda 架构思想
            - Storm 的主要开发者 Nathan Marz 在 Twitter 工作期间，根据多年从事分布式大数据系统的经验总结提炼了 Lambda 架构思想，来解决这类问题。Lambda 架构设计出了一个能满足实时大数据系统关键特性的架构，包括高容错、低延时和可扩展等。Lambda 架构整合离线计算和实时计算、融合不可变性、读写分离和复杂性隔离等一系列架构原则，可以方便集成 Hadoop, Kafka, Storm, Spark, HBase 等各类大数据组建。主要有：批量处理层、实时数据层和服务层。
        3. 组建选型：
            - 批量数据层：Spark --> Cellar 存储（美团自研KV存储系统，基于 LevelDB）
            - 实时数据层：Storm --> Squirrel 存储（美团自研存储系统，基于 Redis）
            - 服务层：基于 Thrift 构建后台 PRC 接口实现。
        4. 存储选型
            - 硬件选择
            - SQL 还是 NoSQL
            - 我们的实践：Cellar + Squirrel
            - 可靠性保证：跨 IDC 多活备份；依赖熔断；服务降级。
    - 人群画像分析系统
        1. 系统设计：标签组合查询示意图、性别数据分布、活跃地区数据分布；
        2. 实时检索：Elasticsearch，一个基于 Apache Lucene 的开源搜索引擎，用 Java 开发，使用 Lucene 作为其核心来实现所有索引和搜索的功能。它的目的是通过简单的 RESTful API 来隐藏 Lucene 的复杂性。
        3. 效果：人群画像分析系统上线后，已经支持了上万份人群检索和人群画像分析报告，在美团内部数据分析、运营等领域发挥了越来越重要的作用。 
    - 其他系统
        - 标签收录系统
    - 线上应用效果
        - 应用类型覆盖运营、商业分析（消息推送类精细化运营）、搜索（用户分析决策支持）、广告（CTR/CPS 等指标优化）、推荐（推荐个性化排序模型特征）、展现（千人千面展现）、反作弊和金融征信（征信建模）等。应用业务效果和应用业务范围依次递减。   

<h3 id="06"> 6. POI（Points of Interest） 实体链接 </h3>

稳定、完整、优质的基础信息单元是一切上游应用的基础。以美团的酒店业务为例，基础信息的单元是 POI，也就是一个酒店。一个优质的 POI 信息库需要包括但不局限于以下指标：POI 信息的完整性、POI 的重复情况、POI 信息的准确性等。在多个酒旅业务应用场景中，我们希望对相同 POI 的不同描述进行关联和聚合。

- **问题的背景与难点**
    - 案例场景：两组 POI 信息，其中一组是美团已有的 POI 信息库（简称库存 POI 库），另一组是我们希望与之进行 POI 实体链接的信息库（简称待选 POI 库）。
    - 目标：希望对两个库中实际实体相同的 POI 建立一对一或者多对一的实体链接关系。
    - 难点：
        - 很难从名字进行判断，需要考虑是否引入该 POI 除去名字外的其他信息。从业务角度出发，新引入的 POI 信息必须具备信息覆盖率高、信息准确性高的特点。
        - 相似性计算量大，两个优化方案。
            1. 通过聚类的方式进行 POI 聚合。适合离线计算。
            2. 通过建立索引的方式缩小比较候选集。 在 POI 实体链接的线上系统中采用此策略，可以很好地将整体流程分成子任务，各个模块之间的耦合度低，便于工程开发。
- **国内酒店 POI 实体链接的解决方案**
    - 酒店 POI 实体链接
        1. 将美团的酒店 POI 所包含的信息找出来。为了提高算法的健壮性和泛化能力，需要考虑哪些字段的覆盖率高、信息的准确性高，并且我们需要保证待选 POI 库中也具有同样的特征。通过考察发现，同时拥有名称、地址、电话、经度、纬度5个字段，我们可以全方位地定位一家酒店。
        2. 判断两个酒店 POI 是否同一实体的相似度计算。
            1. 基于规则的算法：需要分析大量的样本获取，很耗费时间精力。
            2. 通过计算每一个维度进行相似度打分，最后通过预先配置好的权重进行加权求和： 
            3. 本质上是一个二分类问题，通过模型解决。
    - 数据清洗
        - 实现中的数据大多数都不完整、不一致、无法直接进行特征提取。总结了一些清洗规则，比如特殊符号、数字的统一等。 
    - 特征生成
        1. 名称解析模块：对大量酒店 POI 进行观察，发现名称主要包含了酒店所在城市、酒店品牌名、酒店类型、酒店分店名。因此此模块的主要任务是：从酒店全称中提取各个对应的部分，并在酒店名称全称中获取核心部分的内容。
        2. 地址解析模块：通过数据分析发现地址主要包含了酒店的所在省、市行政区、街道、所在楼层、对应地标等。因此，地址解析的主要任务即从酒店地址中提取出各个对应的部分。
        3. 电话解析模块：电话号码包括国家码，区域码，号码本以及分机号码。
        4. 经纬度解析模块：两个子任务（1）判断国内经纬度 POI 是否出现写反的情况，如果写反了，需要修正；（2）计算两个经纬度在空间上的直线距离，将计算好的经纬度作为特征输入到特征向量中即可。
    - 模型选择与效果评估
        - 模型指标：f1-sore
        - 业务指标：提供一批需要进行实体链接的 POI，有多少比例的 POI 可以被系统以极低的误判率（准曲率）自动处理掉（自动处理率），能够减少多少的运营人力。 
    - 索引粒度的配置 
        - 调整索引粒度是平衡比较次数和召回率的手段，设置索引粒度的策略必须遵守一个策略：必须保证召回率。召回率直接决定算法是否可用。
        - 在召回率保证的情况下，通过策略的调整，尽量减少比较次数。所以问题就转变成：在候选集中，哪些 POI 一定不会和待实体链接的 POI 链接成功？可以设置一些策略：比如不同城市的 POI 不需要参与比较；名称上，比如必须包含“酒”和“店”其中一个字等。
        - 策略评估：美团将已有的所有 POI 实体链接关系通过新策略进行候选集推荐，统计（a）本应该实体链接的 POI 是否在推荐出的候选集中，可以计算召回率；（b）一个目标 POI 的候选集的 POI 个数平均值。在保证 (a) 的情况下，尽可能减小 （b）。 
- **其他场景的策略调整**
    - 策略的设计和场景密切相关，因此当场景改变后应该对策略进行适时的调整。 

<h3 id="07"> 7. 评论挖掘 </h3>

在内容为王的“互联网+”时代，用户喜爱和用户主导逐渐成为了服务的倾向主体。评论挖掘为 UGC 应用中的重要一环。评论的真实性和针对性比较强，且以类似众包的姿态存在，相较于游记类文本的多实体共存现象，其对单一实体的描述更深刻、更直观，且获取成本更低。

- **评论挖掘的背景**，顾名思义，是对用户主观做出的评价性内容进行核心思想的挖掘，其包括多维度的主观体验及不同情感倾向的感受反馈。
    - **评论挖掘的粒度**：对于商品粒度的评价体系进行挖掘，理应成为业界关注的焦点。在酒旅业务场景中，基于单个商品的评价标签，更适合公司内部使用，而从线上展示层来说，POI 粒度的评论挖掘才是重中之重。因此 POI 粒度是本文关注的重点。
    - **评论挖掘的维度**：吃、喝、住、行。从酒店业务来说，标签包括4个维度，即硬件维度、软件维度、商品维度和主观维度。值得注意的是，评论挖掘中的标签和用户画像中的标签有所不同，**用户画像中的标签是对 C 端用户进行属性挖掘和行为构建，而评论挖掘中的标签是B端商家进行硬件层面的挖掘和服务层的判断。**
    - **评论挖掘的整合思考**：评论是一种特殊的内容类文本，是长文本和短文本的综合体。并且，从自然语言处理的深层语义角度来看，评论是一种多情感并存的内容类文本。它的明显特征在于，上下文的情感差异可能存在极端情况。 
- **评论标签提取**
    - 两类做法：（1）监督学习，重点在于标注数据的获取；（2）无监督学习，大部分基于统计学原理，采用 TF-IDF 的思想对大量文本中出现的重要词汇进行重要度打分，从而得到批量文本中的关键词语。当然，标签提取在风控领域中被广泛使用基于规则的专家系统。
    - 数据的获取及预处理
         - 噪声数据：繁体字、英文、日韩文字、特殊符号
         - 中文分词：词义消歧、预定义词表、未登陆词、词性标注(Jieba)、命名实体识别(斯坦福大学出品的命名实体)
         - 结构化处理：长句切分、去停用词、去标点符号
         - 词向量化处理：word2vec, golve, random initialize 
    - 无监督的标签提取方法
         - 标签提取是一个需要耗费很多人力的工程，可以通过无监督学习下的标签提取来缓解。
         - 标签提取，又可以看作**关键词抽取**。关键词抽取的常规算法主要包括各类主题模型、比如 LDA, 基于TF-IDF的各类变种算法，以及部分学者提出的基于统计机器翻译的新兴方法论。重点介绍 TextRank，其中阻尼系数的经验值一般为 0.85。 
    - 基于深度学习的标签提取方法 
        - CNN 为例 
        - 流程：数据处理、数据标注、模型训练、模型优化 
- **标签情感分析**
    - 评论标签情感分析的特殊性
        - 对长短不一的内容如何抽取关键情感信息
        - 多标签正负样本杂糅的问题
        - 正负样本不均衡问题 
    - 基于深度学习的情感分析方法
        - TextCNN, TextRNN, CRNN。 
    - 评论标签情感分析的后续优化与思考
        - TextCNN 和 TextRNN 是最易实现且效果不错的解决方案。CRNN 虽然效果较前两者更加优秀，但它主要局限在隐层单元数和批尺寸调整后，其训练时间大大增加，使得方案迭代较慢。
        - Mini-Batch 最好选在 56 以上。
        - 优秀的训练数据才是优化的天花板。因此，当你通过 Grid Search 来调节超参数只能起到微弱作用时，就应该考虑训练样本的正负比例，及其样本的多样性以及正负样本间打乱的程度。  
- **评论挖掘的未来应用及实践**
    - 在后续研究中，我们会将评论挖掘的应用点放在线上 POI 质量的优化、最优评论的挑选与展示、智能识别刷单评论等多个细分领域，同时评论挖掘中的很多模型和方法也存在诸多可以改进和探索之处。更进一步，可以通过神经机器翻译等对目前无法处理的英文、日韩文字等进行翻译和转换，从而增加评论中不同人群的占比，从丰富人文底蕴的层面增加评论的多样性。 

<h2 id="search-recommendation"> 搜索和推荐 </h2>

<h3 id="08"> 8. O2O 场景下的查询理解与用户引导 </h3>

- Introduction
    - Terminology: 查询词、倒排索引、文本域、文档、商家 POI、召回、误召回、品类。  
- **现代搜索引擎原理**
    - 核心：倒排索引 + 布尔检索
- **精确理解查询**
    - 考虑的基本面：意图识别、实体识别（Named Entity Recognition, NER）、词性标注（Part-of-Speech Tagging）、查询改写、紧密度计算、词权重计算、查询纠错。
    - **用户查询意图的定义与识别**
        - 两个问题：
            1. 怎样定义用户的查询意图？
            2. 怎样识别用户的查询意图？
        - 解题的几个思路：
            - 将用户意图看作分类：
                - 核心思想：（1）专家建立分类体系；（2）意图识别 => 分类问题。
                - 优点：原理简单、可控性强、执行难度低；
                - 缺点：意图粒度难以做细、需要大量人工参与。 
            - 将用户意图看作聚类：
                - 核心思想：（1）无监督学习生成多个类簇；（2）意图识别 => 将查询问题归到某个类簇上。
                - 优点：避免人工参与、能够发现人难以观测到的更细粒度的意图。
                - 缺点：确定类簇的个数是一个挑战；可控性更弱，保障效果的难度更大。 
            - 将用户意图看作主题分布：   
                - 核心思想：（1）用户意图被定义为主题概率分布；（2）意图识别 => 将文本转化为主题向量，具体某个维度到底是什么主题可以不关心。
                - 优点：能够细粒度地表示查询
                - 缺点：无监督学习，主题分布往往难以做得精确，需要比较高的实现技巧。
            - 美团实践：
                - 工业实现的精髓在于具体问题具体分析，仔细分析数据、理解业务，从而做处合适于当前场景的选择。两步走：（1）识别查询所属业务；（2）识别出查询词的具体成分。
                - 分类器实现方案有两种——一个多分类器和多个二分类器，我们选择使用多个二分类器：
                - 目的：保证整个框架灵活的扩展性，使其能够跟随业务变化。
                - 弊端：不同分类器输出得分的可比性问题。 
    - **查询实体识别与结构化**
        - 实体识别问题通常被看作求解序列标注，即使用有限的标签集，按序依次对字符做标记。通常使用 IOB2 格式做标记：{I, O, B}。具体解释如下：
            - I (Intermediate): 实体词的中间标记，表示延续； 
            - O (Out): 表示该字符并非实体词的组成部分；
            - B (Begin): 是实体词的中间字符标记。
        - 抽象来看对每一个字符打标签的过程，实际上是对每一个字符进行分类。
        - **条件随机场**在多次评测任务及论文中已经被证明是一种比较好的解决方案。 
        - 一些基于**深度学习**的实体识别方式也出现了，有效减少了人工特征工程。
    - **召回策略的变迁**
        - 在 O2O 搜索中，对商家 POI 的描述可以是品牌名称、地址、品类等多个互相之间相关性并不高的文本域，这些文本域分别描述了商家的某一个侧面。如果对 O2O 搜索引擎也采用全部索引命中求交的方式，误召回就可能会大量产生。
        - 两个问题：
            1. 检索策略是人工设定的，对应的文本域也是人工选择，这种方案较重依赖经验。
            2. 由于需要对整个查询串分词后的每个词项进行求交，只有全部词项都出现在该检索策略对应的文本域中，文档才会被作为候选结果返回。这样仍旧会导致一部分结果无法召回。  
    - **查询改写**
        - 问题：
            - 只通过字面匹配不能召回这些近似等价的结果。
            - “一义多词”和“一词多义”的现象
        - 方法：增、删、改
            - 替换：同义词、缩写词
            - 删除：Term Selection, Term Weighting
            - 扩展：词义、词项、链接分析、Session 挖掘
            - 对齐：Machine Translation
        - Note: 查询改写不一定要发生在查询端，它也可以对索引端做处理。往往将查询端的在线计算与索引端的离线计算结合起来。
    - **词权重与相关性计算**
        - 方法：
            - TF-IDF
            - 基于规则打分
            - 基于统计学习
                - 人工标注训练样本：一种简单的方式即是二值表示，1 为重要，0 为不重要，我们以此构建回归模型。
                - 用户点击共现：人工标注样本集合是耗时耗力的，可以考虑使用用户的点击日志作为标注样本集。一种方式是认为查询词中出现在被点击的文档的展示字段。
        - 作用：
            - 词权重的使用一方面可以用以增加召回结果的相关性，使得排序靠前的结果更相关；另一方面可以用于查询改写，删除相对不重要的词项，这一操作也简称为“去词”，即丢失词项的意思。
            - 查询改写中的去词改写存在着两种不同的思路：
                - 词项选择：思路是主动挑选出重要的词项，要确定的是对每个词项选或不选，而无须具体计算词项的权重分数。
                - 词项权重：先尝试计算出词项的权重，再在其之上设置去词策略。
        - Note: 通常垂直场景下直接用相关性得分排序的效果是不好的，往往最重要的特征都不是相关性，这是由垂直场景的自身特点决定的，比如美团搜索的到餐消费场景下，距离就是一个更重要的特征，所以相关性得分一般都只是作为主排序模型的一个特征来影响最终的排序。
    - **类目相关性与人工标注**
        - 美团的业务专家针对不同的业务制定了不同的品类体系，并且品类体系随着业务的发展不断演化。
        - 美团的信息系统中的每一个对象都会由人工在录入系统时标注到后台叶子品类。这一点类似于淘宝的商品录入，读者可以同时参考淘宝的做法。
        - 通过品类信息做检索，通常由两种方式：筛选、过滤。
    - **查询理解小结** 
        - 查询理解解决的就是两个核心问题：
            1. “找什么”：理解输入。
            2. “怎么找”：系统工程，是相关召回能力。
- **引导用户完成搜索** 
    - **用户引导的产品定义与衡量标准**
        - 如果说查询理解是更纯粹的技术实现，那么用户引导就可以看作是产品设计与技术实现紧密结合的产物了。
        - 引导的百科定义是“带着人们向某个目标行动，在行动上帮助人们走出困境”。
        - 用户引导包括：
            - 搜索前引导：以推荐为主，此时并不知道用户明确的查询意图，典型产品是默认搜索词和热词。
            - 搜索中引导：以补全为主，用户已经输入了部分查询，这是一个明确的提示，我们要做的事根据这个提示做联想和扩展。
            - 搜索后引导：以细化和相关查询词、商家推荐为主，用户一旦使用这类产品，必然是对当前的搜索结果不甚满意。
        - 评估指标：
            - 搜索引导流量占比。
            - 点击率
            - 转化率
        - Note: 在优化过程中，出现指标相悖的情况更看转化，因为一旦效果不佳的策略上线，对用户造成了不好的印象就难以逆转，我们更倾向于一点一点地优质扩量，而不是追求某个指标的短期大幅提升。
    - **搜索前的引导——查询词推荐**
        - 用户引导产品系统架构：数据处理层（候选集的选择有以下几种方式：搜索日志、WiFi 信息、地理位置相关信息、热点信息）、召回策略层、排序层（L1：规则粗排序 -> L2：Learning to Rank -> L3: 后处理规则调整）、展示层。
    - **搜索中的引导——查询补全**
        - 数据处理层：候选集可以有搜索日志、商家数据、地点、品类、行业名词、组合词等。
        - 召回层：前缀匹配是一种符合用户输入行为的召回触发方式
            - 前缀匹配召回的数据结构：Trie 树、HashTable, 倒排索引
            - 前缀匹配召回的数据类型：普通前缀、拼音前缀、简拼前缀
        - 三层排序方式
    - **搜索后的引导——相关搜索**
        - 可以看作是两种不同思路的结合：（1）信息检索；（2）推荐。
    - **效率提升与效果提升**
        - 美团采用四层架构的框架，初期快速迭代时采用独立的方式开发、调试、部署；中后期做产品融合，将底层数据处理流程和排序服务复用，通过参数选择；而召回层实现多种算法可选择配置，在不同的产品上使用不同的组合，来实现差异化。
        - 需要强调的是，处理特征时一定要同时考虑时效性和累积性两个方面。
        - 训练样本的构造：采用一个滑动窗口，通过前 N-1 个用户行为来预测第 N 个用户行为。有了训练样本，妥善地进行特征工程之后，便可以进行监督式学习。
    - **用户引导小结**
        - 用户引导强调技术与产品和设计的结合，需要研发团队的各环节紧密配合，才能取得预期的效果。
        - 几个注意事项：紧密关注用户、取经同行、环位思考、大胆假设。
    - 小结：（几点建议）
        - A/B 测试
        - 用户引导和查询理解相互促进
        - 引导产品是完整体系
        - 给用户选项，但别替用户做决策：任何时候都不要替用户做决策，意图分析是一个概率问题，任何方法都不能保证百分之百的准确率。提供给用户最大概率下的建议，尝试方便用户用户的操作，并给出明确的选项就够了，而不是在某些场景下不得不回退。

<h3 id="09"> O2O 场景下排序的特点 </h3>

- Introduction
    - O2O 场景是复杂多变的，O2O 排序具有移动化、场景化、本地化、个性化 4 个特点。
- **系统概述**
- **在线排序服务**
    - L1 粗粒度排序：使用较少的特征、简单的模型或规则对候选集进行粗粒度排序；
    - L2 细粒度排序：对 L1 排序结果的前 N 个进行细粒度排序；
    - L3 业务规则调整：在 L2 排序的基础上，应用业务规则/人工干预对排序进行适当调整。
- **多层正交 A/B 测试**
    - 采用 UUID 将请求流量切分为多个桶，每个桶对应一种排序策略，桶内流量将使用相应的策略进行排序。
- **特征获取**
    - 细粒度排序过程及不同维度的特征，特征获取和计算是一个耗时的过程，这也成为在线排序服务响应速度的瓶颈。
- **离线调研系统**
    - 主要分为两个部分：特征工程和模型调研。
- **特征工程**
    - 几个关键维度：User 维度、Query 维度、POI 维度、上下文维度、其他。
- **排序模型**
    - 将 LTR 应用到排序的过程中，采用 Pointwise 和 Pairwise 方法，利用用户的点击、下单和支付等行为来进行正样本的标注。另外，为了模拟用户的真实浏览行为，我们进行了 Skip Above 操作。
    - 在学术界，Pairwise 的效果好于 Pointwise，在工业界，Pairwise 也渐渐在各大公司流行起来。其中, LambdaMart 已经成为业界比较流行的 Pairwise 模型，美团的排序模型使用了 RankSVM 和 LambdaMart.
    - Ranklib 是一套非常优秀的 LTR 领域的开源实现，它涵盖了许多 Pointwise, Pairwise 以及 Listwise 模型，可以深入了解各个算法的实现细节，其中包括了 LambdaMart。
- **场景化排序**
    - 流量划分：业务专注 + 方向细化。

<h3 id="10"> 推荐在 O2O 场景中的应用 </h3>

- **典型的 O2O 推荐场景**
    - “猜你喜欢”展位是美团移动端首页的推荐展位，也是美团移动端流量最大的推荐展位。
- **O2O 推荐场景特点**
    - O2O 推荐场景与其他推荐的区别具体包括以下三点：地理位置因素、用户历史行为、实时推荐
    - **O2O 场景的地理位置因素**：概括了不同层次索引的异同点和优缺点，KD-Tree 索引、GeoHash 索引、热门商圈索引、城市维度索引。
    - **O2O 场景的用户历史行为**：实际使用会根据时间衰减。将所有数据都存下来不现实，实际应用会结合用户的活跃度和行为的类别来做相应的截断。截断时会综合考虑线上存储空间的占用和实际效果优化需求来折中考虑，并选择一个性价比较的方案。
    - **O2O 场景的实时推荐**：召回的实时性、特征的实时性、排序模型的实时性。
- **美团推荐实践——推荐框架**
    - 基本可以分为：数据层、候选集触发层、候选集融合规则过滤层和重排序层。
- **美团推荐实践——推荐召回**
    - 个性化推荐的成功应用需要两个条件：（1）信息过载；（2）用户大部分时候没有特别明确的需求。
    - 我们必须通过对数据的清洗去除数据中的噪声，然后通过算法和模型学习其中的规律，才能将数据的价值最大化。
    - 推荐候选集触发过程中用到的相关算法：
        - 基于协同过滤的召回
        - 基于位置的召回
        - 基于搜索查询的召回
        - 基于图的召回
        - 基于实时用户行为的召回
        - 替补策略
            - 替补策略：热销单、好评单、城市单
            - 融合策略：加权型、分级型、调制型、过滤型
- **美团推荐实践——推荐排序**
    - 美团使用了 LTR 技术，使用机器学习来训练到线上的排序模型
    - 排序特征：Item 维度的特征、用户维度的特征、用户和Item的交叉特征、距离特征、场景特征、排序特征处理、排序特征选择、排序特征监控。
    - 排序样本：样本选择、曝光数据的应用、对样本做去噪、样本采样和样本权重。
    - 排序模型：
- **推荐评价指标**
    - 信息维度：点击率 CTR, 万设备点击用户数，万设备点击数，停留时间，阅读深度，收藏数/点赞数；
    - 交易维度：下单率 CVR，支付率，万设备购买数，万设备购买用户数，GMV 交易额，利润；
    - 体验维度：不喜欢率，Bad Case 比例，新颖度，多样性，用户回访周期，用户流失率。

<h2 id="computing-advertising"> 计算广告  </h2>

<h3 id="11"> 11. O2O 场景下的广告营销 </h3>

- **O2O 场景下的广告业务特点**
    - 移动化：主要体现在精确性、即时性和互动性三个方面。
    - 本地化
    - 场景化：消费者、移动设备、时间、空间构成了用户消费需求的精准场景。PC 时代，用户的标识以 Cookie 为载体，但 Cookie 极易清除，同时一台电脑可能会被多人使用，这导致用户信息很难有效串联。
    - 多样性 
- **商户、用户和平台三者利益平衡**
    - **商户效果感知**
        - 商户在美团广告平台上进行广告营销的根本目的：通过美团触达更多的潜在消费者，获得最大的增量利益。
        - 本地生活服务类型的商家的成本可分为两部分：变动成本和固定成本。
        - 广告带来的线上增量收益是指通过在美团等媒体平台上的广告投放带来的线上收益。这一部分收益可以分为两类：（1）直接的在线订单带来的收入；（2）在线预约等非直接交易带来的收益。
        - 对广告效果的衡量需要综合考虑在线和离线两部分收益。
        - 常用的效果评估指标是投入产出比（Return over Investment, ROI）。在广告费预算有限的情况下，商户总是寻求优化广告投放，提升 ROI。 
    - **用户体验**
        - 美团主要从短期和长期两个维度来进行用户体验指标的设计和度量。
        - 短期：主要考虑了点击和交易情况
            - 点击率（Click through Rate, CTR） = 点击次数/曝光次数（为了获取真实的曝光，一般会在移动端进行埋点监控每个 POI 在手机屏幕上实际展现的比例和时间）
            - 转化率（Conversion Rate, CVR）= 交易次数/点击次数
        - 长期：以更长的时间跨度为出发点
            - 回访率：反应用户长期留存的指标，其意义为一定时期内用户是否会重新登陆和使用平台。常用的有周回访率、月回访率等。
            - 复购率：反应了用户消费体验的指标，其意义是一定时期内用户是否会重新购买某一个商家的服务。
    - **平台收益** 
        - 流量变现效率衡量单位流量所能带来的广告收益。
            - 流量变现效率： 
                - 展示广告：千次广告展示收益（Revenue per Mille, RPM）
                - 搜索广告：单次搜索广告收益（Revenue per Search, RPS）
            - 广告收入：
                - 从流量供给端来看：广告收入 = 曝光次数 * CTR * CPC
                - 从流量需求端来看：广告收入 = 广告主数 * ARPU (Average Revenue per User)   
- **O2O 广告机制设计**
    - **广告位设定**
    - **广告召回机制**
        - 搜索广告匹配中，一项重要技术是查询改写。一方面，我们使用传统的自然语言处理方法，对查询进行有效分析（例如成分分析），完成同义和近义改写；另一方面，我们使用深度语义相似度神经网络模型（DSSM）和序列到序列模型（Sequence to Sequence）进行查询改写，进一步提升广告匹配的覆盖率和准确性。
        - 相关性水准考虑多种相关性因素：查询匹配模式、距离和星级等。例如针对 Query 匹配模式，广告召回时会优先使用 Query 精确匹配模式召回，其次选择模糊匹配模式，最后才尝试采用语义匹配模式。 
    - **广告排序机制**
        - 机制核心：
            1. 计算 RankScore = bid * CTR，并基于此进行排序；
            2. 依据广义第二价格（Generalized Second Price）进行计费。charge(i) = (CTR(i+1) * bid(i+1)) / CTR(i)
        - 准确地预测广告的点击率是保障广告收入和用户体验的前提：
            1. 逻辑回归模型：
                - 优势：无约束的凸优化问题，有全局唯一的最优解。支持大规模特征，并能较快收敛。可解释性十分良好。
                - 劣势：线性模型，表达能力较弱，需要做大量的特征工程。需要进行大量的特征预处理工作，比如归一化、离散化等。 
            2. 因子分解机 FM 模型和场感知因子分解机 FFM 模型
                - FM 和 FFM 都是非线性模型，它们对特征进行两两组合，提升了模型的表达能力；并且都对特征进行向量化表达和学习，提升了模型的泛化能力。
                - FFM 相对于 FM 引入了域的概念，在 FM 中特征 i 和其他特征组合用的是同一个向量表示，而在 FFM 中特征 i 和不同域特征组合会使用不同的向量表示，进一步提升了模型的复杂度和表达力。
            3. 人工神经网络（ANN）
                - Wide & Deep: Wide 部分可以类比逻辑回归模型，能对相关特征的作用进行很好的记忆；Deep 部分类似 FM 模型和 FFM 模型，它们都对相关特征进行了向量化的表示和学习，并且通过复杂的网络结构可以表达更复杂的特征交互和组合关系，提供了更好的泛化能力和表达力。
- **O2O 推送广告**
    - Introduction
        - 推送广告就是媒体在合适的时机将合适的广告以消息的形式推送给合适的人群。
        - 实现精准触达，需要做到两点：完整的用户画像 + 智能匹配技术。
        - 推送广告的特点是：主动触达、用户意图不明确。因此相比于搜索广告，推送广告更需要精准的受众定向。  
    - 受众定向：
        - 常用定向方式：时间定向；重定向；地理位置类定向；人口属性定向；行为定向；新客推荐。 
        - 实现广告和用户的匹配：（1）为广告的受众人群进行初步假设，即确定广告感兴趣的人群，并将其与用户画像标签映射起来，这一步要靠产品调研和分析得到；（2）根据这个初步假设确定广告投放的定向条件，匹配到符合条件的人群。
            - 单个定向条件的表示
            - 组合定向条件的表示
            - 定向条件匹配
            - 定向效果评价：（1）质：点击率和转化率；（2）量：覆盖程度，指用户覆盖率、广告使用率以及定向方式对应的流量占比。
        - 经验：在美团推送广告中，重定向方式点击率和转化率最好，但覆盖率最低；地理位置定向和人口属性标签拥有更广泛的人群，效果相对较差。  
- **O2O 广告系统工具** 
    - **面向开发人员的系统工具**
        - 离线数据分析工具、实时数据分析工具以及在线广告系统调试工具。 
    - **面向广告主和运营人员的工具**
        - 效果漏斗分析工具、推广实况工具、流失订单分析工具、广告收益模拟器。 
 
 <h3 id="12"> 12.用户偏好和损失建模  </h3>

- **如何定义用户偏好**
    - **什么是用户偏好**
        - 用户偏好，即用户对某些主题、某些事物有不同程度的匹配价值和接受程度。 
        - 在 O2O 场景下，用户的商圈偏好、地理位置偏好、品类偏好、价格偏好、消费时间偏好等，都是用户偏好在不同主题上个人意愿和消费诉求的体现。
        - 完整的用户偏好 = 长期偏好 + 即时意图  
    - **如何衡量用户偏好**
        - 偏好强度存在如下关系：POI 下单 > POI 点击 > POI 曝光
        - 如果使用模型来学习用户偏好的这个程度关系，就需要在建模过程中考虑这些偏序关系。比如 Pairwise。
    - **对不同 POI 的偏好**
        - 采用量化的方法来衡量用户对某个店的不同兴趣程度，以排好用户看到的商家列表。 
    - **用户对 POI 偏好的衡量** 
        - 排序学习的经典模型：Pointwise, Pairwise, Listwise。 
- **广告价值与偏好损失的兑换**
    - **优化目标**
        - 多目标优化问题：用户体验、商家利益、平台收益
            - 对于用户来说，最快时间找到自己最想要找的店铺进而消费即可。指标是 CTR 和 CVR。
            - 对于广告主来说，他想导流让更多用户看到自己的店，进而尽快或以后到店消费。指标有：点击量、转化量、ROI
            - 对于平台来讲，它既要让用户体验尽量不受损伤，维持用户在平台的黏性，也要尽量给商家创造价值，将商家闲置的资源利用起来，让整个市场更有效。因此他要同时考虑用户指标和商家指标。
        - 优化 case：
            - 比如在平台收益情况不变的情况下，鼓励用户浏览其更可能点击进而转化的商户。
            - 比如保证用户体验不变差的情况下，鼓励用户浏览感兴趣的广告商户，从而提高商户的点击量。   
    - **模型建模**
        - 曝光价值、点击价值、下单价值 
    - **Pairwise 模型学习** 
        - GBRank, RankNet. 

<h2 id="deeplearning"> 深度学习 </h2>

<h3 id="13"> 13. 深度学习概述</h3>

这部分主要概述了深度学习的发展历程，和几类典型的深度神经网络：(Deep Feed Forward Neural Network, DFFNN), (Convolution Neural Network, CNN), (Recurrent Neural Network, RNN)，进一步可参考 Bengio <Deep Learning> 的书。

目前主要突破领域：图片分类、语音识别和机器翻译。

三次迎来发展的好时机：（1）1943 年到 1986 年：1943 年 W.S.McCulloch 和数理逻辑学家 W.Pitts 提出了人工神经元模型 MCP，这可看作人工神经网络的起点；1957 年，Rosenblatt 发明了感知机算法 Perceptron；1968 年，好景不长，美国数学家和人工智能先驱 Minsky 证明了感知机是一种线性模型，它只能处理线性分类问题，因此神经网络陷入了第一次近 20 年的停止期。（2）1986 年到 2006 年：1986 年，Hinton 发明了多层感知机（MLP）的反向传播（BP）算法，从而解决了神经网络只能解决线性分类的问题，引发了第二轮热潮；1900 年，支持向量机如火如荼的发展起来，神经网络存在梯度消失和爆炸、难以解释的问题一直低迷到 2006 年。（3）2006 年至今：2006 年，Hinton 有了重大发明，提出了无监督分层初始化方法结合深度玻尔兹曼机（Deep Boltzmann Machine, DBM）解决了深层神经网络梯度消失等难题，这项发明刊登在 Science 上，开启了深度学习第三次研究热潮；2012 年，AlexNet 在 ImageNet 比赛夺冠；2015 年至今，深度学习在语音、图像、自然语言处理领域取得突破，谷歌、微软、脸书、百度等纷纷开源其深度学习框架和模型，极大推进了各领域应用深度学习的进程。

研究热点：基于深度学习的生成式模型、深度强化学习。

<h3 id="14"> 14. 深度学习在文本领域中的应用 </h3>

- Introduction
    - 文本领域大致可分为 4 个维度：词、句子、篇章、系统应用。
- 基于深度学习的文本匹配
    - 应用场景：搜索的 Query 和 Doc、广告中 Query-Ad、搜索 Suggestion 中 Query 前缀和 Query 、关键词推荐中 Query 和 Query 、文档去重时 Doc 和 Doc 等。
    - 核心：文本匹配主要研究计算两段文本的相似度问题。相似度问题包含两层
        1. 两段文本如何表示可使得计算机方便处理，这需要研究不同的表示方法效果的区别；
        2. 如何定义相似度来作为优化目标，如语义匹配相似度、点击关系相似度、用户行为相似度等。
    - 语义表示匹配模型演进历程
        - 向量空间：
            - 1970 年左右
            - TF-IDF, BM25, ...
                - TF-IDF 从信息论的角度包含了词和文档的点互信息熵，以及文档的信息编码长度。
                - 度量相似度的方法有：Jaccard, Cosine, Euclidean distance, BM25等，其中 BM25 是衡量文档匹配相似度非常经典的方法。
            - 优点：简单实用，且效果不错，目前仍然是各检索系统必备的特征。
            - 缺点：维度过高，不能解决同义词、多义词问题
        - 矩阵分解：
            - 1990 年左右
            - LSA, ...
            - 优点：可解决维度过高问题
            - 缺点：物理含义弱
        - 主题模型：
            - 2000 ～ 2015 年，以概率图模型为基础的主题模型掀起了一股热潮。
            - pLSA (99'), LDA(03'), ...
                - pLSA (Probabilistic Latent Semantic Analysis)：
                    - 对文档的建模不再是矩阵分解，而是概率分布（比如多项式分布） 
                    - 参数空间很大，容易过拟合。因而人们引入多项式分布的共轭分布来做贝叶斯建模，即 LDA 使用的方法。
                - LDA (Latent Dirichlet Allocation)
                    - 若果说 pLSA 是频度学派代表，那 LDA 就是贝叶斯学派代表。
                    - LDA 通过引入 Dirichlet 分布作为多项式共轭先验，在数学上完整解释了一个文档生成过程。
                    - 不足：对短文本推断效果不好、训练参数多速度慢、引入随机过程建模避免主题数目人工设定不合理问题等。随着研究进一步发展，这些问题基本都得到了较好的解决，比如针对速度慢问题有：LDA --> SparseLDA, AliasLDA --> LightLDA, WarpLDA。
            - 优点：数学完备、物理意义明确
        - 深度学习：
            - 2013 年至今
            - Word2Vec (13'), DSSM(13'), ClickNet, ...
                - 2003 年，Yoshua Bengio 的语言模型，奠定了基础。
                - 2013 年，Tomas Mikolov 发表了 Word2Vec 相关的论文，提出的两个模型 CBOW (Continuous BagofWords，连续词袋)和 Skip-Gram。不足：该模型的学习目标是预测词发生概率，即语言模型，所以从海量语料中学习到的是词的通用语义信息，无法直接应用于定制业务的匹配场景。
                - DSSM 的系列工作，解决 Word2Vec 的不足
                    - DSSM 模型框架
                    - CLSM
                    - LSTM-DSSM  
                - 美团的 ClickNet，结合语言层信息和用户意图、用户状态。
            - 优点：考虑了语义，语法   
- 基于深度学习的排序模型
    - 排序模型简介
        - 应用场景：在搜索、广告、推荐、问答等系统中，由于需要在召回的大量候选集中选择出有限的几个用于展示，因此排序是很重要的一环。
        - 排序模型主要分三类：Pointwise, Pairwise, Listwise。 
    - 深度学习排序模型的演进
        - RankNet，
            - 是 Pairwise 的模型，同样转化为 Pointwise 来处理。
            - 后续研究发现，RankNet 以减少错误 Pair 为优化目标，对 NDCG 等指标（关心相关文档所在位置）衡量的效果不是太好，于是后面出现了改进模型，如 LambdaRank。 
            - 在工业界用得多的还是简单的线性模型，如逻辑回归，线性模型通过大量的人工设计特征来提高效果，模型解释性好性能也高。
        - Wide & Deep 
            - 输入都是稀疏特征，但特征分为两种：
                1. 合适做 Deep 的深度网络变化，适合时效性或者记忆性的特征，比如统计特征或者展示位置等；
                2. 另一种可以直接连在最外层，适合有推广力但需要深度组合抽样的特征，比如品类、类型等。
            - 目前应用较广，比如阿里巴巴就有比较好的应用。
        - YouTube DNN 排序模型
            - YouTube 用来预测用户观看视频时长，转化为加权的逻辑回归问题。
            - 虽然深度学习模型对特征工程要求很低，但很多数据需要经过简单处理后才可加入模型。
            - 在做排序模型中，输出特征的选取和表示方式是很重要的，比如连续特征、离散特征处理、文档特征的区分等。
    - 美团的深度学习排序模型尝试
        - ClickNet-v1：业务特征选取、特征离散化、样本处理、信息的融合。
        - ClickNet-v2：以业务特征为主，替换业务 Rank 模型为目标。     
        
<h3 id="15"> 15. 深度学习在计算机视觉中的应用 </h3>

- 基于深度学习的 OCR 技术
    - 美团的主要应用场景：（1）辅助录入；（2）审核校验。
    - OCR 技术发展历程
    - 基于深度学习的文字检测：（1）受控场景的文字检测；（2）非受控场景的文字检测。
    - 基于序列学习的文字识别
- 基于深度学习的图像智能审核
    - 基于深度学习的水印检测
    - 明星脸识别：人脸检测、人脸识别
    - 色情图片检测
    - 场景分类  
- 基于深度学习的图像质量排序
    - 图像美学质量评价
    - 面向点击预测的图像质量评价

其他：本章内容没有认真看，计算机视觉是一个大领域，可先理解其作用和应用场景，后续若需要再进一步深入。 

<h2 id="algorithm-engineering"> 算法工程 </h2>

<h3 id="16"> 16. 大规模机器学习 </h3>

- Introduction
    - 传统单机机器学习系统：样本数都在数千至数数万规模，特征维度比较稀少，大概控制万维规模一下。
    - 机器学习的趋势从传统方法中的简单模型+少量数据（人工标注样本），到简单模型+海量数据（比如基于逻辑回归的广告点击率预测），再发展到现在复杂模型 + 海量数据。
    - 大规模机器学习的常用场景：广告 CTR 预估，聚类算法 K-means、谱聚类等，主题模型 LDA、PLSA、Word2Vec等，协同过滤 User-Base、Item-Base，深度学习。 
- 并行计算编程技术
    - 向量化
        - 向量化计算是一种特殊的并行计算方式，相比于一般程序在同一时间只执行一个操作的方式，它可以在同一时间执行多个操作，通常是对不同的数据执行同样一个或一批指令，或者说把指令应用于一个数组/向量。 
    - 多核并行 OpenMP
        - 多线程相对于机器学习来说，并行存在的问题：
            1. 多线程编程技术的开发成本较高，而且此技术需要妥善处理同步互斥等问题；
            2. 不同平台使用的多线程编程库是不一样的，这样也会造成移植性问题。
    - GPU 编程
        - 事实证明在浮点运算、并行计算等部分计算方面，GPU 可以提供数十倍乃至上百倍于 CPU 的性能。目前 GPU 生产的主要厂商有 NVIDIA、ATI(AMD)、Intel，其中 NVIDIA 是最大的独立显卡生产商，而 Intel 主要生产集成显卡。目前主流的 GPU 计算解决方案 CUDA 主要是 NVIDIA 提供的，如果用的是其他显卡，则目前安装不了 CUDA 及其相关的工具包。 
    - 多机并行 MPI
    - 并行编程技术小结
        - 向量化和 OpenMP。在单机执行机器学习训练的情况下，主要采用该技术进行加速，使用该技术常用的开源机器学习包有 XGBoost, Multi-core Liblinear, Libffm 和 FANN。
        - GPU 编程（CUDA）。几乎所有的深度学习包都会使用该技术，比如 Theano, MXNet, TensorFlow, 和 Caffe。
        - MPI。有些大公司也开发了自己的消息通信系统，其功能上与 MPI 大同小异，Graphlab, Distributed MPI LIBLINEAR, Paracel 都是采用 MPI 的代表。 
- 并行计算模型
    - 随着大数据技术的发展，分布式系统越来越多。我们熟知的用于批处理的 MapReduce 系统 Hadoop、基于内存的 MapReduce 的 Spark 系统是 Job 中间输出结果，可以保存在内存中、实时流处理系统 Storm，以及后起之秀面向分布式数据流处理和批量数据处理的开源计算机平台 Flink。
    - 分布式机器学习任务与传统的分布式任务之间的区别：
        - 传统的 MapReduce 模型计算过程中一旦发生错误，错误是会一直传播而不会得到任何修正的。
        - 对于机器学习程序来说，中间结果的错误是可以容忍的，有多条路径都可以收敛到最优。
        - 机器学习算法却比传统的 MapReduce 程序拥有更加复杂的结构依赖，就是说机器学习模型中的参数通常不是独立的。
        - 机器学习算法还有一个特性是参数收敛速度的不均匀，MapReduce 排序把数据分发到不同节点执行，各节点的任务和负载基本上是均衡的。
    - 分布式机器学习系统需要解决如下三个问题：
        - 如何更好切分成多个任务
        - 如何调度子任务
        - 均衡各节点的负载。
    - 具体来说其实主要是梯度下降求解的并行化问题，针对最优化求解并行化提出了很多并行模型：  
        - BSP：较早的一个并行计算模型，也是当前主流的并行计算模型之一。
        - SSP：缓解 BSP 的问题。BSP 模型在每一轮结束之后都需要进行一次同步，这很容易造成木桶效应。
        - ASP：
        - 参数服务器：是近年来在分布式机器学习领域非常火的一种技术。参数服务器是一个编程框架。
- 并行计算案例
    - XGBoost 并行库 Rabit
    - MXNet 并行库 PS-Lite
- 美团并行计算机器学习平台 
    - Ginger，主要组件包括：存储部分（Stores, Tensor），模型组件部分（Layer, Net, Model），控制部分（Engine, Updator），并行库（Parallel Lib）和在线预测（Online Pred）。   

<h3 id="17"> 17. 特征工程和实验平台 </h3>

在使用机器学习的方法解决领域内实际问题的时候，最重要也是最关键的一步就是将线下训练好的模型部署到实际的生产环境中。本章将结合美团实际业务领域中的真实应用场景，分别介绍机器学习中的两大支柱工程——特征平台和实验平台。

- 特征平台
    - 特征生产
        - 离线特征生产
            1. 离线存储：Hive, MySQL, HBase, ES, NoSQLDB
            2. 特征计算
                - ETL(Extract-Transform-Load)：
                    - 优点：开发逻辑简单、快速、标准化、易验证，因此它是快速生产简单特征的首选。
                    - 缺点：不适于复杂特征计算。另外 SQL 的执行性能、可读性以及可管理性也是 ETL 流程存在的欠缺。
                - Hadoop Map-Reduce/Spark
                    - 优点：可以利用 SDK 提供的接口实现更为复杂和精细的特征生产流程，也能够支持更多不同的开发语言。是业务场景中广广泛用来作为特征生成的方式。此方式更适应于大数据时代的计算。
            3. 定时调度
                - 注册任务
                - 依赖分析
                - 生产计划 
        - 实时特征生产
            - 主要分为三个步骤：业务数据生产、数据的收集和数据的处理。
            - 特征计算的逻辑集中在给定的流式计算引擎框架下的开发，所以实时特征计算的重点就在于流式数据的处理。预期延迟？吞吐量？状态跟踪？  
    - 特征上线 
        - 键值特征加载框架：DataHub
            - 元数据管理平台 （DataHub Console）：主要提供数据源的配置和管理的功能，主要对象是提供数据的用户。
            - 数据加工平台（DataHub Service）：核心模块，核心任务是对元数据管理平台中注册的数据同步进行导入和加工，具体是将各种异构、不同来源、不同维度的数据统一到 DataHub 的数据体系中来。可以同时支持离线数据和实时数据的导入。
            - 数据获取客户端（DataHub Client）
        - 服务特征加载框架
            - 线上特征加载流程中，除了有上节提到的从缓存读取的键值特征之外，还有一类特征是通过远程服务调用（Remote Procedure Call, RPC）从其他的远程服务获取的，并且这些特征之间存在着时序上的依赖关系。这种类型的特征在加载上存在着两个难点：（1）特征加载的时间性能一定能程度上依赖于被调用服务的响应时间；（2）特征加载存在着时序上的依赖。 
        - 复合特征加载框架 
            - 一个能够灵活配置特征组合，线上加载复合特征的框架。 
    - 在线特征监控
        - 特征监控的内容
            - 过程监控：主要关注特征生产的过程中可能出现的问题；核心内容包括：上游依赖的数据量的监控、上游响应时间的监控、加工过程异常数量的监控、加工过程处理时间的监控等。
            - 结果监控：主要是对已经生成好的特征进行校验和监控；核心内容：更多依赖于特征生产者的一些先验知识，对每个特征项事先进行分析和统计得出特征的值域区间、最大值、最小值、均值、中位数、区间分布、方差等一系列指标，并将其作为基准值。
        - 特征监控的手段
        - 特征异常后的通知和处理 
- 实验管理平台
    - 实验平台概述
        - A/B Test 的常见的应用场景应该满足以下几个条件：
            - 优化场景：A/B Test 并不能给出解决方案，而只是辅助我们对若干候选方案进行选择。
            - 量化指标：常关注的有 PV, UV, CTR, CVR, CPM 等。
            - 用户稳定：需要保证整体实验的群体稳定且不受客观条件的干扰。
            - 长期反馈：要尽量控制实验之外的影响因素保持固定。
        - 在进行实验设计、操作和结果分析的过程中，以下两个问题需要重点关注：
            - 实验流量分配：每个分支的实验保证分配的正交性、均匀性、充足性。
            - 排除实验自身干扰：常见的且容易忽视的自身干扰因素包括改进的方案和策略带来系统性能的下降、稳定性的下降等。
        - 一个优秀的 A/B Test 框架需要满足以下特性才能完美支持实验的三个阶段：
            - 快速构建实验。
            - 随时上下线实验。
            - 同时支持多组实验。    
    - 美团实验平台——Gemini  
        - 静态缓存服务器。
        - 业务服务器（Client Lib）
        - 实验平台
            - 垂直划分实验功能。
            - 独占流量实验。
            - 克隆实验。  
            - 在线修改实验配置。
            - 自定义实验调试。
            - 关联实验。
            - 自动启停实验。
            - 灰度发布。
        - 日志收集与数据中心。