{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_ROOT = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadSimData():\n",
    "    # for algorithm test\n",
    "    dataMat = np.array([[ 1. ,  2.1],\n",
    "        [ 2. ,  1.1],\n",
    "        [ 1.3,  1. ],\n",
    "        [ 1. ,  1. ],\n",
    "        [ 2. ,  1. ]], dtype='float')\n",
    "    classLabels = np.array([1.0, 1.0, -1.0, -1.0, 1.0], dtype='float')\n",
    "    return dataMat, classLabels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(dataMat[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.3  1. ]\n",
      "(2, 2)\n",
      "[[ 1.   2.1]\n",
      " [ 2.   1.1]\n",
      " [ 2.   1. ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f3b65303750>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataMat, classLabels = loadSimData()\n",
    "uniqueClass = np.unique(classLabels)\n",
    "class1 = uniqueClass[0]\n",
    "class2 = uniqueClass[1]\n",
    "\n",
    "plt.figure()\n",
    "dataClass1 = dataMat[classLabels == class1, :]\n",
    "print(dataClass1[:,0])\n",
    "print(np.shape(dataClass1))\n",
    "plt.scatter(dataClass1[:,0], dataClass1[:,1], c='r', label = 'class1')\n",
    "dataClass2 = dataMat[classLabels == class2, :]\n",
    "print(dataClass2)\n",
    "plt.scatter(dataClass2[:,0], dataClass2[:,1], c='g', label = 'class2')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.xlim([min(dataMat[:,0])-0.5, max(dataMat[:,0])+0.5 ])\n",
    "plt.ylim([min(dataMat[:,1])-0.5, max(dataMat[:,1])+0.5 ])\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## weak classifier realization: one layer decistion tree (stump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stumpClassify(dataArr, dimen, threshVal, threshIneq):\n",
    "    retPredArr = np.ones((np.shape(dataArr)[0], 1))\n",
    "    if threshIneq == 'lt':\n",
    "        retPredArr[dataArr[:,dimen] <= threshVal] = -1\n",
    "    else:\n",
    "        retPredArr[dataArr[:,dimen] > threshVal] = -1\n",
    "    \n",
    "    return retPredArr\n",
    "\n",
    "def buildStump(dataArr, labelsArr, weights, numSteps = 10.0):\n",
    "    m, n = np.shape(dataArr)\n",
    "    labelsArr = labelsArr.reshape(len(labelsArr), 1)\n",
    "    print(labelsArr.shape)\n",
    "    bestStump = {}\n",
    "    bestClassEst = np.zeros((m, 1))\n",
    "    minError = np.inf\n",
    "    for i in range(n): # traverse each feature\n",
    "        rangeMin = min(dataArr[:,i])\n",
    "        rangeMax = max(dataArr[:,i])\n",
    "        stepSize = (rangeMax - rangeMin) / numSteps\n",
    "        for j in range(-1, np.int(numSteps)+1):\n",
    "            for inequal in ('lt', 'gt'):\n",
    "                threshVal = rangeMin + float(j)*stepSize\n",
    "                predicVal = stumpClassify(dataArr, i, threshVal, inequal)\n",
    "                errArr = np.ones((m, 1))\n",
    "                errArr[labelsArr == predicVal] = 0\n",
    "                errWeighted = np.sum(weights*errArr)\n",
    "                #print(\"dim = %d threshold = %.2f, inequal = %s, errWeighted = %.3f\" % (i, threshVal, inequal, errWeighted))\n",
    "                if errWeighted < minError:\n",
    "                    minError = errWeighted\n",
    "                    bestClassEst = predicVal\n",
    "                    bestStump['dim'] = i\n",
    "                    bestStump['thresh'] = threshVal\n",
    "                    bestStump['ineq'] = inequal\n",
    "    return bestStump, minError, bestClassEst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1)\n",
      "dim = 0 threshold = 0.90, inequal = lt, errWeighted = 2.000\n",
      "dim = 0 threshold = 0.90, inequal = gt, errWeighted = 3.000\n",
      "dim = 0 threshold = 1.00, inequal = lt, errWeighted = 2.000\n",
      "dim = 0 threshold = 1.00, inequal = gt, errWeighted = 3.000\n",
      "dim = 0 threshold = 1.10, inequal = lt, errWeighted = 2.000\n",
      "dim = 0 threshold = 1.10, inequal = gt, errWeighted = 3.000\n",
      "dim = 0 threshold = 1.20, inequal = lt, errWeighted = 2.000\n",
      "dim = 0 threshold = 1.20, inequal = gt, errWeighted = 3.000\n",
      "dim = 0 threshold = 1.30, inequal = lt, errWeighted = 1.000\n",
      "dim = 0 threshold = 1.30, inequal = gt, errWeighted = 4.000\n",
      "dim = 0 threshold = 1.40, inequal = lt, errWeighted = 1.000\n",
      "dim = 0 threshold = 1.40, inequal = gt, errWeighted = 4.000\n",
      "dim = 0 threshold = 1.50, inequal = lt, errWeighted = 1.000\n",
      "dim = 0 threshold = 1.50, inequal = gt, errWeighted = 4.000\n",
      "dim = 0 threshold = 1.60, inequal = lt, errWeighted = 1.000\n",
      "dim = 0 threshold = 1.60, inequal = gt, errWeighted = 4.000\n",
      "dim = 0 threshold = 1.70, inequal = lt, errWeighted = 1.000\n",
      "dim = 0 threshold = 1.70, inequal = gt, errWeighted = 4.000\n",
      "dim = 0 threshold = 1.80, inequal = lt, errWeighted = 1.000\n",
      "dim = 0 threshold = 1.80, inequal = gt, errWeighted = 4.000\n",
      "dim = 0 threshold = 1.90, inequal = lt, errWeighted = 1.000\n",
      "dim = 0 threshold = 1.90, inequal = gt, errWeighted = 4.000\n",
      "dim = 0 threshold = 2.00, inequal = lt, errWeighted = 3.000\n",
      "dim = 0 threshold = 2.00, inequal = gt, errWeighted = 2.000\n",
      "dim = 1 threshold = 0.89, inequal = lt, errWeighted = 2.000\n",
      "dim = 1 threshold = 0.89, inequal = gt, errWeighted = 3.000\n",
      "dim = 1 threshold = 1.00, inequal = lt, errWeighted = 1.000\n",
      "dim = 1 threshold = 1.00, inequal = gt, errWeighted = 4.000\n",
      "dim = 1 threshold = 1.11, inequal = lt, errWeighted = 2.000\n",
      "dim = 1 threshold = 1.11, inequal = gt, errWeighted = 3.000\n",
      "dim = 1 threshold = 1.22, inequal = lt, errWeighted = 2.000\n",
      "dim = 1 threshold = 1.22, inequal = gt, errWeighted = 3.000\n",
      "dim = 1 threshold = 1.33, inequal = lt, errWeighted = 2.000\n",
      "dim = 1 threshold = 1.33, inequal = gt, errWeighted = 3.000\n",
      "dim = 1 threshold = 1.44, inequal = lt, errWeighted = 2.000\n",
      "dim = 1 threshold = 1.44, inequal = gt, errWeighted = 3.000\n",
      "dim = 1 threshold = 1.55, inequal = lt, errWeighted = 2.000\n",
      "dim = 1 threshold = 1.55, inequal = gt, errWeighted = 3.000\n",
      "dim = 1 threshold = 1.66, inequal = lt, errWeighted = 2.000\n",
      "dim = 1 threshold = 1.66, inequal = gt, errWeighted = 3.000\n",
      "dim = 1 threshold = 1.77, inequal = lt, errWeighted = 2.000\n",
      "dim = 1 threshold = 1.77, inequal = gt, errWeighted = 3.000\n",
      "dim = 1 threshold = 1.88, inequal = lt, errWeighted = 2.000\n",
      "dim = 1 threshold = 1.88, inequal = gt, errWeighted = 3.000\n",
      "dim = 1 threshold = 1.99, inequal = lt, errWeighted = 2.000\n",
      "dim = 1 threshold = 1.99, inequal = gt, errWeighted = 3.000\n",
      "dim = 1 threshold = 2.10, inequal = lt, errWeighted = 3.000\n",
      "dim = 1 threshold = 2.10, inequal = gt, errWeighted = 2.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'dim': 0, 'ineq': 'lt', 'thresh': 1.3}, 1.0, array([[-1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [ 1.]]))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.ones((5,1))\n",
    "dataArr, labelsArr = loadSimData()\n",
    "buildStump(dataArr, labelsArr, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realization the AdaBoost Algorithm\n",
    "```\n",
    "    for each iteration:\n",
    "        find the best decision stump by 'buildStump()' function  \n",
    "        add the best decision stump into the whole array of week classifier  \n",
    "        calculate the 'alpha'  \n",
    "        update the vector of weights\n",
    "        update the aggregate class estimated value\n",
    "        \n",
    "        if error == 0.0:\n",
    "            break\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adaBoostTrainDS(dataArr, labelsArr, numIter = 40):\n",
    "    weakClassifierList = []\n",
    "    labelsArr = labelsArr.reshape(len(labelsArr), 1)\n",
    "    m = dataArr.shape[0]\n",
    "    weights = np.ones((m,1))/m  # initial weight is 1/m\n",
    "    aggClassEst = np.zeros((m,1))\n",
    "    \n",
    "    for i in range(numIter):\n",
    "        bestStump, error, classEst = buildStump(dataArr, labelsArr, weights)\n",
    "        #print(\"weights: \", weights.T)\n",
    "        alpha = float( 0.5 * np.log( (1-error)/max(error, 1e-16) ) ) # max(error, 1e-16) avoid overflow\n",
    "        bestStump['alpha'] = alpha\n",
    "        weakClassifierList.append(bestStump)\n",
    "        #print(\"classEst\", classEst.T)\n",
    "        \n",
    "        # labelsArr * classEst = 1 : classify accurately , so exp(-1*alpha)\n",
    "        # labelsaRR * classEst = -1 : classify error, so exp(alpha)\n",
    "        expon = (-1*alpha*(labelsArr*classEst.reshape(len(classEst),1)))\n",
    "        weights = weights * np.exp(expon)\n",
    "        weights = weights / np.sum(weights)\n",
    "        \n",
    "        aggClassEst += alpha * classEst # vote class by weights\n",
    "        #print(\"aggClassEst: \", aggClassEst.T)\n",
    "        aggErrors = (np.sign(aggClassEst) != labelsArr) * np.ones((m, 1))\n",
    "        \n",
    "        errorRate = np.sum(aggErrors) / m\n",
    "        print(\"total error : \", errorRate)\n",
    "        \n",
    "        if errorRate == 0.0 : \n",
    "            break\n",
    "    \n",
    "    return weakClassifierList, aggClassEst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1)\n",
      "('total error : ', 0.20000000000000001)\n",
      "(5, 1)\n",
      "('total error : ', 0.20000000000000001)\n",
      "(5, 1)\n",
      "('total error : ', 0.0)\n",
      "[{'dim': 0, 'ineq': 'lt', 'thresh': 1.3, 'alpha': 0.6931471805599453}, {'dim': 1, 'ineq': 'lt', 'thresh': 1.0, 'alpha': 0.9729550745276565}, {'dim': 0, 'ineq': 'lt', 'thresh': 0.90000000000000002, 'alpha': 0.8958797346140273}]\n"
     ]
    }
   ],
   "source": [
    "dataArr, labelsArr = loadSimData()\n",
    "weakClassifierList,_ = adaBoostTrainDS(dataArr, labelsArr)\n",
    "print(weakClassifierList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost classify for unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adaClassify(dataArr, classifierList):\n",
    "    dataArr = np.mat(dataArr)\n",
    "    m,n = dataArr.shape\n",
    "    aggClassEst = np.zeros((m,1))\n",
    "    for i in range(len(classifierList)):\n",
    "        classifier = classifierList[i]\n",
    "        classEst = stumpClassify(dataArr, \n",
    "                                 classifier['dim'], \n",
    "                                 classifier['thresh'], \n",
    "                                 classifier['ineq'])\n",
    "        aggClassEst += classifier['alpha'] * classEst\n",
    "        #print(aggClassEst.T)\n",
    "    \n",
    "    return np.sign(aggClassEst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaClassify([0,0], weakClassifierList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.],\n",
       "       [ 1.]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaClassify([[0,0], [5,5]], weakClassifierList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A real case :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadDataSet(filename):\n",
    "    numFeat = len( open(filename).readline().split('\\t') )\n",
    "    dataList = []\n",
    "    labelsList = []\n",
    "    fr = open(filename)\n",
    "    for line in fr.readlines():\n",
    "        curLineList = line.split('\\t')\n",
    "        attributeList = [ float(x) for x in curLineList[:-2]]\n",
    "        dataList.append(attributeList)\n",
    "        # map the original label \n",
    "        # 1 -> 1\n",
    "        # 0 -> -1\n",
    "        curLabel = float(curLineList[-1])\n",
    "        if curLabel == 1.0:\n",
    "            labelsList.append(curLabel)\n",
    "        else:\n",
    "            labelsList.append(-1.0)\n",
    "    return np.array(dataList), np.array(labelsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2.     1.    38.5   66.    28.     3.     3.     0.     2.     5.\n",
      "     4.     4.     0.     0.     0.     3.     5.    45.     8.4    0. ]\n",
      " [   1.     1.    39.2   88.    20.     0.     0.     4.     1.     3.\n",
      "     4.     2.     0.     0.     0.     4.     2.    50.    85.     2. ]\n",
      " [   2.     1.    38.3   40.    24.     1.     1.     3.     1.     3.\n",
      "     3.     1.     0.     0.     0.     1.     1.    33.     6.7    0. ]\n",
      " [   1.     9.    39.1  164.    84.     4.     1.     6.     2.     2.\n",
      "     4.     4.     1.     2.     5.     3.     0.    48.     7.2    3. ]\n",
      " [   2.     1.    37.3  104.    35.     0.     0.     6.     2.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.    74.     7.4    0. ]]\n",
      "[-1. -1.  1. -1. -1.]\n",
      "(299, 1)\n",
      "('total error : ', 0.28428093645484948)\n",
      "(299, 1)\n",
      "('total error : ', 0.28428093645484948)\n",
      "(299, 1)\n",
      "('total error : ', 0.24749163879598662)\n",
      "(299, 1)\n",
      "('total error : ', 0.24749163879598662)\n",
      "(299, 1)\n",
      "('total error : ', 0.25418060200668896)\n",
      "(299, 1)\n",
      "('total error : ', 0.24080267558528429)\n",
      "(299, 1)\n",
      "('total error : ', 0.24080267558528429)\n",
      "(299, 1)\n",
      "('total error : ', 0.22073578595317725)\n",
      "(299, 1)\n",
      "('total error : ', 0.24749163879598662)\n",
      "(299, 1)\n",
      "('total error : ', 0.23076923076923078)\n",
      "(299, 1)\n",
      "('total error : ', 0.24080267558528429)\n",
      "(299, 1)\n",
      "('total error : ', 0.21404682274247491)\n",
      "(299, 1)\n",
      "('total error : ', 0.22742474916387959)\n",
      "(299, 1)\n",
      "('total error : ', 0.21739130434782608)\n",
      "(299, 1)\n",
      "('total error : ', 0.22073578595317725)\n",
      "(299, 1)\n",
      "('total error : ', 0.21739130434782608)\n",
      "(299, 1)\n",
      "('total error : ', 0.22408026755852842)\n",
      "(299, 1)\n",
      "('total error : ', 0.22408026755852842)\n",
      "(299, 1)\n",
      "('total error : ', 0.23076923076923078)\n",
      "(299, 1)\n",
      "('total error : ', 0.22408026755852842)\n",
      "(299, 1)\n",
      "('total error : ', 0.21404682274247491)\n",
      "(299, 1)\n",
      "('total error : ', 0.20735785953177258)\n",
      "(299, 1)\n",
      "('total error : ', 0.22073578595317725)\n",
      "(299, 1)\n",
      "('total error : ', 0.21070234113712374)\n",
      "(299, 1)\n",
      "('total error : ', 0.20401337792642141)\n",
      "(299, 1)\n",
      "('total error : ', 0.20401337792642141)\n",
      "(299, 1)\n",
      "('total error : ', 0.20401337792642141)\n",
      "(299, 1)\n",
      "('total error : ', 0.20735785953177258)\n",
      "(299, 1)\n",
      "('total error : ', 0.21070234113712374)\n",
      "(299, 1)\n",
      "('total error : ', 0.21070234113712374)\n",
      "(299, 1)\n",
      "('total error : ', 0.20066889632107024)\n",
      "(299, 1)\n",
      "('total error : ', 0.21404682274247491)\n",
      "(299, 1)\n",
      "('total error : ', 0.20735785953177258)\n",
      "(299, 1)\n",
      "('total error : ', 0.22408026755852842)\n",
      "(299, 1)\n",
      "('total error : ', 0.21739130434782608)\n",
      "(299, 1)\n",
      "('total error : ', 0.22408026755852842)\n",
      "(299, 1)\n",
      "('total error : ', 0.21739130434782608)\n",
      "(299, 1)\n",
      "('total error : ', 0.21404682274247491)\n",
      "(299, 1)\n",
      "('total error : ', 0.20401337792642141)\n",
      "(299, 1)\n",
      "('total error : ', 0.20401337792642141)\n"
     ]
    }
   ],
   "source": [
    "dataArr, labelsArr = loadDataSet(DATA_ROOT + 'horseColicTraining.txt')\n",
    "print(dataArr[:5, :])\n",
    "print(labelsArr[:5])\n",
    "classifierList,_ = adaBoostTrainDS(dataArr, labelsArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.    1.   38.5  54.   20.    0.    1.    2.    2.    3.    4.    1.\n",
      "    2.    2.    5.9   0.    2.   42.    6.3   0. ]\n",
      " [  2.    1.   37.6  48.   36.    0.    0.    1.    1.    0.    3.    0.\n",
      "    0.    0.    0.    0.    0.   44.    6.3   1. ]\n",
      " [  1.    1.   37.7  44.   28.    0.    4.    3.    2.    5.    4.    4.\n",
      "    1.    1.    0.    3.    5.   45.   70.    3. ]\n",
      " [  1.    1.   37.   56.   24.    3.    1.    4.    2.    4.    4.    3.\n",
      "    1.    1.    0.    0.    0.   35.   61.    3. ]\n",
      " [  2.    1.   38.   42.   12.    3.    0.    3.    1.    1.    0.    1.\n",
      "    0.    0.    0.    0.    2.   37.    5.8   0. ]]\n",
      "[ 1.  1.  1. -1.  1.]\n",
      "13.0\n",
      "0.194029850746\n"
     ]
    }
   ],
   "source": [
    "dataTestArr, labelsTestArr = loadDataSet(DATA_ROOT + 'horseColicTest.txt')\n",
    "print(dataTestArr[:5,:])\n",
    "print(labelsTestArr[:5])\n",
    "predClass = adaClassify(dataTestArr, classifierList)\n",
    "errArr = np.ones((len(predClass), 1))\n",
    "labelsTestArr = labelsTestArr.reshape(len(labelsTestArr), 1)\n",
    "errorNum = errArr[predClass != labelsTestArr].sum()\n",
    "errorRate = errorNum / len(predClass)\n",
    "print(errorNum)\n",
    "print(errorRate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## non-uniform dataset & ROC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotROC(predStrengthsArr, classLabelsArr):\n",
    "    predStrengthsArr = np.array(predStrengthsArr)\n",
    "    classLabelsArr = np.array(classLabelsArr)\n",
    "   \n",
    "    numPositive = sum(classLabelsArr == 1)\n",
    "    numNegative = len(classLabelsArr) - numPositive\n",
    "    yStepSize = 1.0 / float(numPositive)\n",
    "    xStepSize = 1.0 / float(numNegative)\n",
    "    \n",
    "    print(\"numPositive : %d, numNegative: %d, yStepSize = %.2f, xStepSize = %.2f\"\n",
    "          % (numPositive, numNegative, yStepSize, xStepSize))\n",
    "    \n",
    "    sortedIndexs = predStrengthsArr.argsort()\n",
    "    \n",
    "    cur = (1.0, 1.0)  # start point to plot, all of elements are marked as positive \n",
    "    ySum = 0.0 # for AUC calculation\n",
    "    plt.figure()\n",
    "    plt.clf()\n",
    "    \n",
    "    for i in sortedIndexs: # iteration to add negative element\n",
    "        # [0...i] negative\n",
    "        # [i+1, .. end] positive\n",
    "        if classLabelsArr[i] == 1.0: \n",
    "            # error, positive instance is classified as negative\n",
    "            # which will lead the TPR decrease\n",
    "            delx = 0\n",
    "            dely = yStepSize\n",
    "        else: \n",
    "            # correct, negative instance is classified as positive\n",
    "            # which will lead the FPR decrease\n",
    "            delx = xStepSize\n",
    "            dely = 0\n",
    "            ySum += cur[1]\n",
    "        \n",
    "        plt.plot([cur[0], cur[0] - delx], [cur[1], cur[1] - dely], c='b') # line segment\n",
    "        cur = (cur[0]-delx, cur[1]-dely)\n",
    "    \n",
    "    plt.plot([0,1], [0,1], 'b--') # baseline\n",
    "    plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "    plt.ylabel(\"True positive Rate (TPR)\")\n",
    "    plt.title(\"ROC\")\n",
    "    plt.xlim([0,1])\n",
    "    plt.ylim([0,1])\n",
    "    plt.show()\n",
    "    # for calculation of AUC:\n",
    "    # for each iteration appove we got a small rectangle with hight yi = cur[1] and wid xStepSize\n",
    "    # so the Area = [y0*xStepSize + y1*xStepSize + ... + yn*xStepSize] = [y0+y1+...+yn]*xStepSize = ySum*xStepSize\n",
    "    print(\"The Area Under the Curve (AUC) is :\", ySum*xStepSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2.     1.    38.5   66.    28.     3.     3.     0.     2.     5.\n",
      "     4.     4.     0.     0.     0.     3.     5.    45.     8.4    0. ]\n",
      " [   1.     1.    39.2   88.    20.     0.     0.     4.     1.     3.\n",
      "     4.     2.     0.     0.     0.     4.     2.    50.    85.     2. ]\n",
      " [   2.     1.    38.3   40.    24.     1.     1.     3.     1.     3.\n",
      "     3.     1.     0.     0.     0.     1.     1.    33.     6.7    0. ]\n",
      " [   1.     9.    39.1  164.    84.     4.     1.     6.     2.     2.\n",
      "     4.     4.     1.     2.     5.     3.     0.    48.     7.2    3. ]\n",
      " [   2.     1.    37.3  104.    35.     0.     0.     6.     2.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.    74.     7.4    0. ]]\n",
      "[-1. -1.  1. -1. -1.]\n",
      "(299, 1)\n",
      "('total error : ', 0.28428093645484948)\n",
      "(299, 1)\n",
      "('total error : ', 0.28428093645484948)\n",
      "(299, 1)\n",
      "('total error : ', 0.24749163879598662)\n",
      "(299, 1)\n",
      "('total error : ', 0.24749163879598662)\n",
      "(299, 1)\n",
      "('total error : ', 0.25418060200668896)\n",
      "(299, 1)\n",
      "('total error : ', 0.24080267558528429)\n",
      "(299, 1)\n",
      "('total error : ', 0.24080267558528429)\n",
      "(299, 1)\n",
      "('total error : ', 0.22073578595317725)\n",
      "(299, 1)\n",
      "('total error : ', 0.24749163879598662)\n",
      "(299, 1)\n",
      "('total error : ', 0.23076923076923078)\n",
      "(299, 1)\n",
      "('total error : ', 0.24080267558528429)\n",
      "(299, 1)\n",
      "('total error : ', 0.21404682274247491)\n",
      "(299, 1)\n",
      "('total error : ', 0.22742474916387959)\n",
      "(299, 1)\n",
      "('total error : ', 0.21739130434782608)\n",
      "(299, 1)\n",
      "('total error : ', 0.22073578595317725)\n",
      "(299, 1)\n",
      "('total error : ', 0.21739130434782608)\n",
      "(299, 1)\n",
      "('total error : ', 0.22408026755852842)\n",
      "(299, 1)\n",
      "('total error : ', 0.22408026755852842)\n",
      "(299, 1)\n",
      "('total error : ', 0.23076923076923078)\n",
      "(299, 1)\n",
      "('total error : ', 0.22408026755852842)\n",
      "(299, 1)\n",
      "('total error : ', 0.21404682274247491)\n",
      "(299, 1)\n",
      "('total error : ', 0.20735785953177258)\n",
      "(299, 1)\n",
      "('total error : ', 0.22073578595317725)\n",
      "(299, 1)\n",
      "('total error : ', 0.21070234113712374)\n",
      "(299, 1)\n",
      "('total error : ', 0.20401337792642141)\n",
      "(299, 1)\n",
      "('total error : ', 0.20401337792642141)\n",
      "(299, 1)\n",
      "('total error : ', 0.20401337792642141)\n",
      "(299, 1)\n",
      "('total error : ', 0.20735785953177258)\n",
      "(299, 1)\n",
      "('total error : ', 0.21070234113712374)\n",
      "(299, 1)\n",
      "('total error : ', 0.21070234113712374)\n",
      "(299, 1)\n",
      "('total error : ', 0.20066889632107024)\n",
      "(299, 1)\n",
      "('total error : ', 0.21404682274247491)\n",
      "(299, 1)\n",
      "('total error : ', 0.20735785953177258)\n",
      "(299, 1)\n",
      "('total error : ', 0.22408026755852842)\n",
      "(299, 1)\n",
      "('total error : ', 0.21739130434782608)\n",
      "(299, 1)\n",
      "('total error : ', 0.22408026755852842)\n",
      "(299, 1)\n",
      "('total error : ', 0.21739130434782608)\n",
      "(299, 1)\n",
      "('total error : ', 0.21404682274247491)\n",
      "(299, 1)\n",
      "('total error : ', 0.20401337792642141)\n",
      "(299, 1)\n",
      "('total error : ', 0.20401337792642141)\n"
     ]
    }
   ],
   "source": [
    "dataArr, labelsArr = loadDataSet(DATA_ROOT + 'horseColicTraining.txt')\n",
    "print(dataArr[:5, :])\n",
    "print(labelsArr[:5])\n",
    "classifierList, aggClassEst= adaBoostTrainDS(dataArr, labelsArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numPositive : 178, numNegative: 121, yStepSize = 0.01, xStepSize = 0.01\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiAAAAGHCAYAAACJeOnXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe9891827d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The Area Under the Curve (AUC) is :', 0.8918191104095093)\n"
     ]
    }
   ],
   "source": [
    "plotROC(aggClassEst[:,0], labelsArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
