### 《机器学习在线：解析阿里云机器学习平台》-2017

[9.16~9.19, 9.25]

本书其实最主要是对阿里机器学习平台的介绍，读书时可主要关注「平台思想」、「算法流程设计」、「应用场景」。至于其中的细节，可以参考对应理论相关的书，个人仍觉得一口气看完较好，这样能有更好的全局视野。相关的理论应该是之前都已经掌握的，如果没有掌握则可以关注方法的功能和优缺点，后期再进一步细化细节。

本书涉及了分类、回归预测、聚类、特征工程等机器学习方法在实际中的应用。其中有关推荐的章节可进一步阅读《推荐系统实践》-项亮-2012。电商另外一个热点应用是广告，可以进一步阅读《计算广告》-刘鹏-2015。文本分析可以进一步阅读《Neural Network Methods in Natural Language Processing》-Yoav Goldberg-2017。情感分析可以进一步阅读《Sentiment analysis and opinion mining》-Liu, Bing-2012， 主要是传统的方法，不过可以对情感分析有全貌的了解。如果想了解 tensorflow，还是建议官网的 tutorial。基于 python 的机器学习模型可以通过 sklearn 实现。总的来说，还是要多积累。

### 目录

- [阿里云机器学习](#01)
- [商家作弊行为检测](#02)
- [生存预测](#03)
- [信用风险预测](#04)
- [用户购买行为预测](#05)
- [聚类与分类](#06)
- [葡萄酒品质预测](#07)
- [文本分析](#08)
- [基于用户退货描述的赔付预测](#09)
- [情感分析](#10)
- [影片推荐](#11)
- [支持深度学习框架](#12)

<h3 id="01"> 阿里云机器学习 </h3>

- [阿里云机器学习网址](https://data.aliyun.com/product/learn)， 构建在 MaxCompute 之上。
- 产品特点：简单、易用；算法丰富、完整；支持处理大数据。
- 名词解释：MaxCompute，项目（Project），实验（Experiment），MaxCompute 源表与 MaxCompute 目标表（Table），组件（Nodes），分区（Partition）.


<h3 id="02"> 商家作弊行为检测 </h3>

- Motivation: 电子商务领域是一块大蛋糕，个别商家通过作弊的手段希望获得更多利润，譬如：虚假交易就是一种重要的作弊方式，凭借此提升商家的等级，骗取用户的信任。
- Task: 通过对交易行为的分析，预测商家作弊情况。分类问题。
- Data: `Transaction_id`, `a_score`, `b_score`, `r_score`, `p_score`, `ri_score`, `v_score`, `label`. (Node `_score` 都通过某种操作规范化到了 `[0,1]` 范围)。
- Data Explore: 
	- data information(count, missing, min, max, std), label distribution. 
	- 各属性的直方图
	- 在类别划分上不同属性的概率密度（看某个属性对“分类”的能力）
- Model, Forecasting, Evaluation
	- Mode: Naive Bayes.
	- Evaluation: 二分类评估（AUC, F1-score），混淆矩阵  
- 尝试其他分类模型：logistic regression，random forest.
- 判断商家作弊：需要构造出两种典型商家的数据，分层采样，固定随机种子复现实验。

<h3 id="03"> 生存预测 </h3>

- Motivation: 如果解决多分类问题
- Task: 多分类
- Demo1
	- Data: kaggle Titantic 事件：`class`, `age`, `sex`, `survived`.
	- Data Expore, 特征分析：Entropy, Gini, Gini Gain, Info Gain, Info Gain Ratio.
	- Model:Naive Bayes, Random Forest
- Demo2
	- Data: kaggle Titantic 所有数据属性
	- 过拟合（random forest）：
		- 现象：train-0.999，test-0.889  	
		- detection：观察决策树中叶节点属性个数，对应太少数据说明该属性过拟合（其中 ticket=constant，没有泛化能力，把这个属性删除）。 
	- naive bayes model

<h3 id="04"> 信用风险预测 </h3>

- Motivation: 是否能有某种某种变化或方法，使 logistic regression 也可以使用枚举类型的离散特征呢？——**讲述特征哑元化的方法**。(可以参考 python 中的 [pandas.get_dummies.html](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html))
- Data: [German Credit Data Set ](http://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data)). Attributes: `status`, `duration`, `credit_history`, `purpose`, `credit_amount`, `savings`, `employment`, `installment_rate`, `marriage_sex`, `debtors`, `residence`, `property`, `age`, `other_plan`, `housing`, `number_credits`, `job`, `maintenance_num`, `telephone`, `foreign_worker`.
- Modle:
	- 几点注意：（1）dummy 是通过 SQL 组件实现的；（2）dummy 不仅对训练数据进行，还要处理测试数据；（3）logistics regression 得到每个属性的重要性（我在阿里实习的时候是这么做的）
- Evaluation: (a table)
	- LR vs. RF vs. GBDT
	- Metrics: Precision, Recall, Confusion Matrix, Ratio Matrix  
- 减少模型特征的个数（选择重要特征）：
	- Motivation: 模型特征的可解释性、模型的大小等因素。
	- L1 Regularization or not. 

<h3 id="05">用户购买行为预测 </h3>

- Motivation: 如何构造生成新的特征
- Data: 2014 年的阿里巴巴大数据竞赛第一赛季。Attributes: `user_id`, `time`(day), `action_type`(click-0, buy-1, collect-2, shopping-cart-3), `brand_id`.
- Task: 根据用户在天猫的行为日志，建立用户的品牌偏好，并预测他们将来对品牌下商品的购物行为。
- Evaluation: 我们希望预测的品牌**准确率**越高越好，也希望**覆盖**的用户和品牌越多越好，所以常用**准确率**和**召回率**作为排行榜的指标。
	- 准确率（Precision）: `$ P = \frac{\sum_{i=1}^{N}hitBrands_{i}}{\sum_{i=1}^{N}pBrands_{i}} $`, `$N$`表示预测的用户数,`$pBrands_{i}$`表示对用户 i 预测他（她）会购买的品牌列表个数，`$ hitBrands_{i} $` 表示用户 i 预测的品牌列表与用户 i 真实购买的品牌交集的个数。
	- 召回率（Recall）或称灵敏度（Sensitivity）：`$ R = \frac{\sum_{i=1}^{M}hitBrands_{i}}{\sum_{i=1}^{M}bBrands_{i}} $`, `$M$` 为实际产生成交的用户数量，`$bBrands_{i}$`为用户 i 真实购买的品牌个数。
	- F1-score: `$ F_{1} = \frac{2PR}{P+R} $`
- Data Expore: 数据量，完整性，比例，相关性。
- 特征：
    - 三个维度：用户特征/品牌特征/用户-品牌特征 （计数/转化特征）
    - 时间粒度：近3天、1周、1月、2月、3月、全量
    - 特征类型：
        - 关注：点击数、购买数、收藏数、加购数
        - 变化率【通过数值的变化率来刻画关注的持续程度】：点击变化率（近 3 天的点击数/近4-6天的点击数）、购买变化率、收藏变化率、加入购物车变化率
        - 转化率：点击转化率（少次点击产生了一次购买）、收藏转化率（多少次收藏转化为一次购买）、加入购物车转化率
- 二分类模型：
    - 训练数据集中的每一条记录是关于某个用户对某个品牌的购买行为。
    - 数据集划分/构建
        - 2014.4.15 ~ 2014.7.15（构造特征）: 3 个月数据，用于计算上述特征；「某用户对某品牌是否会在下个月发生购买行为可以通过查询2014.4.15 ~ 2014.7.15时间段内的行为获知」。
        - 2014.7.16 ~ （构造标签）：可以统计出在这段时间内哪些用户、品牌发生了购买行为，用来构建标签。如果某一条记录（`user_id`, `brand_id`）被特征表覆盖并且产生了购买行为则 label=1，否则 label=0.
    - 正负样本配比：label=0:42272, label=1:259，严重失衡。通过对label=0的样本进行分层采样的到 labe=l:1813, label=0:259 (7:1，比例不绝对)。
    - 模型：LR, RF（是否采样）。结论：RF 结果优，并且采样有现在优化效果。
        

<h3 id="06"> 聚类与分类 </h3>

- Data: iris. `sepal`, `sepal_width`, `petal_length`, `petal_width`, `class`.
- Data Expore: 二位散点图矩阵
- K-Means：
    - 迭代过程的可视化展示
    - 原始类别和聚类类别的对比
    - k 的选择
- KNN
    - evaluation: accuracy, Kappa, MacroAveraged


<h3 id="07"> 葡萄酒品质预测 </h3>

- Motivation: 介绍回归模型
- Data: [UCI-Wine Quality Data Set](http://archive.ics.uci.edu/ml/datasets/Wine+Quality)
- Data Expore: quality 的分布情况，11 个特征的相关性分析（相关性系数/散点图）
- 模型：
    - 线性回归、GBDT
- Evaluation: RMSE, MAE, 残差直方图

<h3 id="08"> 文本分析 </h3>

- Motivation: 很多文本数据，比如：新闻的标题和内容、电影评论、商品描述等等。
- Task: 从这些文本数据中，如何寻找**相似的内容**？新闻中的**关键词**是什么？用户评论了一段话，表示的意思是**喜欢还是不喜欢**？
    - 基本内容：比如：分词、词频统计、TF-IDF等。
    - 赔付预测和情感分析
- Data: 爬虫获取的新浪网页数据。`docid`, `category`, `title`, `content`, `time`, `url`. 872256 条数据。
- 基本内容：
    - 分词：基于 AliWS(Alibaba Word Segmenter)词法分析系统。
    - remove stop words：可以依据不同场景定制化停词表
    - 词频统计: `(docid, word, count)`, `(word, count)`
    - 单词的区分度：TF-IDF(Term Frequency - Inverse Document Frequency), TF(Term Frequency), IDF(Inverse Document Frequency).
    - 字符串比较：
        - 常用的距离函数有，编辑距离（Levenshtein Distance）、最长公共子串（Longest Common Substring, LCS）、余弦相似性、Jaccard 相似度、谱核相似度等。本节使用**Levenshtein Distance**。
        - function：字符串相似性、字符串相似性-topN
            - 和 title 最相似的 content (title, content) pair.
            - 2013 年前的每条新闻，可以找到 N 条与其最“接近”的 2013 年及以后的新闻。
    - 抽取关键词、关键句：
        - motivation：文档中的关键词和关键句，是对详细文档内容的一种提炼和总结，可以体现文档的基本内容，帮助用户迅速了解文档所关注的领域，所持的基本观点。
        - TextRank 是 PageRank 在文本领域的应用和改进，主要用于文本生成关键字和摘要。
            - PageRank: `$PR(p_{i}) = (1-d) + d\sum_{p_{k} \in In(p_{i})}\frac{1}{|Out(p_{k})|} PR(p_{k})$`
            - TextRank: `$TR(T_{i}) = (1-d) + d\sum_{T_{k} \in In(T_{i})} \frac{w_{ki}}{\sum_{T_{j} \in Out(T_{k})}w_{kj}}TR(T_{k})$`, d 是阻尼系数，一般设置为 0.85。
        - 通过 TextRank 计算关键词，关键句（可以构成文本摘要）。
- 主题模型
    - task：计算出多少个主题，主题个数是控制主题粒度的关键参数。
    - Topic Model 有几个经典的方法：潜在语意分析（Latent Semantic Analysis, LSA）, 概率潜在语意分析（Probabilistic Latent Semantic Analysis, PLSA），Latent Dirichlet Allocation (LDA)。这些模型的共同点是：忽略每个文档中单词出现的顺序，文档是由出现了哪些单词和每个单词出现的个数，即词袋（bag of words）决定的。
    - 每个主题的关键词展示看区别，权重是对主题的贡献。
- 单词映射为向量：
    - word2vec ----> 相似性度量、聚类 （距离函数的对比选择是关键，通过 case analysis 来主观判断）。

<h3 id="09"> 基于用户退货描述的赔付预测 </h3>

- Motivation: 在电子商务中，有时由于商品的原因，给用户造成了损失，除了退货还涉及对用户进行赔付的问题。
- 目标：二分类，是(1)否(0)赔付
- Data：用户退货描述赔付表，`doc_id`, `label`, `content`。
- 实现：
    - 数据划分：0.8-train，0.2-test
    - 几个关键点：
        1. 使用常用的文本转换特征方式：分词、停用词过滤、词频统计、TF-IDF 计算、转换为 kv 格式（bag-of-words 的形式维度太大，用稀疏方式存储）。
        2. 需要将标记的数据集分为 trainset 和 testset
        3. 在这个应用中，更关注需要赔付的样本，希望对于那些需要赔付的样本预测出的比例更大，即**希望分类模型有更高的召回率**。
    - Evaluation: ROC,K-S curve, Precision, Recall
    - 提高 Recall: 通过分层采样来控制 positive/negative 样本的比例，对比不同采样比例对模型的影响。

<h3 id="10"> 情感分析 </h3>

- Task: 如何通过机器学习算法，高效地判断出评论的情感倾向？
- Data: stanford 的公开数据集，https://nlp.stanford.edu/sentiment/
- 解题：
    - word embedding: bag-of-words, word2vec (8 elements)
    - models: LR, RF, GBDT
    - note: 可以把 word2vec 中的 vector 中的每个元素看成一个属性，然后通过LR的权重，概率密度图等分析每个维度的重要性和差异。

<h3 id="11"> 影片推荐 </h3>

- Data: 公开的影评数据，[MovieLens](https://movielens.org/), `movieid`, `title`, `genres`.
- 方法：使用的推荐算法为推荐领域比较常用的协同过滤方法。
- 协同过滤（Collaborative Filtering）（user-item table）（常用余弦和JaccardSim相似性）
    - User-based: 找到与你相似用户，他喜欢的很有可能你也喜欢。
    - Item-based: 同时被更多人观看过的影片，相似度更高；根据你的观影记录，关联出相似度高的影片推荐。
- 基本流程：
    1. 预处理，过滤出好评信息
    2. 计算影片间的相似性
    3. 计算用户可能喜欢的影片（注意去重，去看过的影片）
- Evaluation: 查看推荐效果，主观判断。

<h3 id="12"> 支持深度学习框架 </h3>

主要介绍了 tensorflow。